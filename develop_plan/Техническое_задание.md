–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ: –ú–æ–¥—É–ª—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è solid-state-kinetics
1. –û–ø–∏—Å–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
1.1 –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º LoggerManager

–ú–æ–¥—É–ª—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤ –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–µ–∫—Ç solid-state-kinetics —á–µ—Ä–µ–∑ –∫–∞—Å—Ç–æ–º–Ω—ã–π Handler, –≤—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –≤ LoggerManager. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç "–Ω–∞ –ª–µ—Ç—É" –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é –≤ —Ñ–∞–π–ª/–∫–æ–Ω—Å–æ–ª—å.

src/
‚îú‚îÄ‚îÄ gui/                    # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π GUI –º–æ–¥—É–ª—å
‚îú‚îÄ‚îÄ core/                   # –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –æ—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
‚îú‚îÄ‚îÄ log_aggregator/         # –ù–û–í–´–ô –º–æ–¥—É–ª—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ realtime_handler.py # –ö–∞—Å—Ç–æ–º–Ω—ã–π Handler –¥–ª—è LoggerManager
‚îÇ   ‚îú‚îÄ‚îÄ buffer_manager.py   # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—É—Ñ–µ—Ä–∞–º–∏ –≤ –ø–∞–º—è—Ç–∏
‚îÇ   ‚îú‚îÄ‚îÄ pattern_detector.py # –î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –ø–æ—Ç–æ–∫–µ
‚îÇ   ‚îú‚îÄ‚îÄ aggregation_engine.py # –î–≤–∏–∂–æ–∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
‚îÇ   ‚îú‚îÄ‚îÄ error_expansion.py  # –ù–û–í–´–ô: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ tabular_formatter.py # –ù–û–í–´–ô: –¢–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
‚îÇ   ‚îî‚îÄ‚îÄ config.py          # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ test_log_aggregator/ # –¢–µ—Å—Ç—ã –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è

1.2 –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏

–ú–æ–¥—É–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 6 –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:

AggregatingHandler (–≤—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –≤ LoggerManager)
‚îú‚îÄ‚îÄ BufferManager         # –ë—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è –ª–æ–≥–æ–≤ –≤ –ø–∞–º—è—Ç–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫–Ω–∞–º–∏
‚îú‚îÄ‚îÄ PatternDetector       # –î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –ø–æ—Ç–æ–∫–µ –¥–∞–Ω–Ω—ã—Ö
‚îú‚îÄ‚îÄ AggregationEngine     # –ê–≥—Ä–µ–≥–∞—Ü–∏—è "–Ω–∞ –ª–µ—Ç—É" —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
‚îú‚îÄ‚îÄ ErrorExpansionEngine  # –ù–û–í–´–ô: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥ –æ—à–∏–±–æ–∫
‚îú‚îÄ‚îÄ TabularFormatter      # –ù–û–í–´–ô: –¢–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
‚îî‚îÄ‚îÄ ConfigManager         # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏

1.3 –ü—Ä–∏–Ω—Ü–∏–ø—ã –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏–Ω–≤–∞–∑–∏–≤–Ω–æ—Å—Ç—å: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Handler –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–¥–∞
–ë—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫–Ω–∞–º–∏ –∏ –ª–∏–º–∏—Ç–∞–º–∏
–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –ê–≥—Ä–µ–≥–∞—Ü–∏—è "–Ω–∞ –ª–µ—Ç—É" –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –±–µ–∑ –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Å–∏—Å—Ç–µ–º—É
–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –æ—à–∏–±–æ–∫: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è WARNING/ERROR –∑–∞–ø–∏—Å–µ–π
–¢–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–¥—É–ª–µ–π
2.1 –ú–æ–¥—É–ª—å AggregatingHandler (realtime_handler.py)

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ö–∞—Å—Ç–æ–º–Ω—ã–π Handler –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ LoggerManager —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

import logging
import threading
from typing import Optional, Dict, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class LogRecord:
    timestamp: datetime
    level: str
    filename: str
    line_number: int
    message: str
    raw_record: logging.LogRecord

class AggregatingHandler(logging.Handler):
    """
    –ö–∞—Å—Ç–æ–º–Ω—ã–π Handler –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
    –í—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π LoggerManager –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞.
    """
    
    def __init__(self, 
                 target_handler: logging.Handler,
                 buffer_size: int = 1000,
                 flush_interval: float = 2.0,
                 min_pattern_entries: int = 3,
                 enabled: bool = True,
                 enable_error_expansion: bool = True,
                 enable_tabular_format: bool = True,
                 error_context_lines: int = 5):
        """
        Args:
            target_handler: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π handler (console/file)
            buffer_size: –†–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ –≤ –ø–∞–º—è—Ç–∏
            flush_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–±—Ä–æ—Å–∞ (—Å–µ–∫—É–Ω–¥—ã)
            min_pattern_entries: –ú–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
            enabled: –í–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏—é
            enable_error_expansion: –í–∫–ª—é—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
            enable_tabular_format: –í–∫–ª—é—á–∏—Ç—å —Ç–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            error_context_lines: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—à–∏–±–æ–∫
        """
        super().__init__()
        self.target_handler = target_handler
        self.enabled = enabled
        self.enable_error_expansion = enable_error_expansion
        self.enable_tabular_format = enable_tabular_format
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        self.buffer_manager = BufferManager(buffer_size, flush_interval)
        self.pattern_detector = PatternDetector(min_pattern_entries)
        self.aggregation_engine = AggregationEngine()
        
        # –ù–û–í–´–ï –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.error_expansion_engine = ErrorExpansionEngine(error_context_lines)
        self.tabular_formatter = TabularFormatter()
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞–º–∏
        self._lock = threading.RLock()
        self._flush_timer: Optional[threading.Timer] = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_records': 0,
            'aggregated_records': 0,
            'patterns_detected': 0,
            'buffer_flushes': 0,
            'errors_expanded': 0,
            'tables_generated': 0
        }
    
    def emit(self, record: logging.LogRecord) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–π –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"""
        if not self.enabled:
            # –ü—Ä—è–º–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –±–µ–∑ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
            self.target_handler.emit(record)
            return
        
        try:
            with self._lock:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç
                log_record = self._convert_record(record)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫—É –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                if self._is_error_record(log_record) and self.enable_error_expansion:
                    self._handle_error_immediately(log_record)
                    return
                
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä
                self.buffer_manager.add_record(log_record)
                self.stats['total_records'] += 1
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
                if self._should_aggregate():
                    self._process_buffer()
                
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∞–π–º–µ—Ä–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–±—Ä–æ—Å–∞
                self._schedule_flush()
                
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ - –ø—Ä—è–º–∞—è –ø–µ—Ä–µ–¥–∞—á–∞
            self.target_handler.emit(record)
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π handler
            self._log_error(f"Aggregation error: {e}")
    
    def _is_error_record(self, record: LogRecord) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø–∏—Å—å –æ—à–∏–±–∫–æ–π"""
        return record.level in ['WARNING', 'ERROR', 'CRITICAL']
    
    def _handle_error_immediately(self, record: LogRecord) -> None:
        """–ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        expanded_record = self.error_expansion_engine.expand_error(
            record, 
            self.buffer_manager.get_recent_context()
        )
        self.target_handler.emit(expanded_record)
        self.stats['errors_expanded'] += 1
    
    def _convert_record(self, record: logging.LogRecord) -> LogRecord:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è LogRecord –≤ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç"""
        return LogRecord(
            timestamp=datetime.fromtimestamp(record.created),
            level=record.levelname,
            filename=record.filename,
            line_number=record.lineno,
            message=record.getMessage(),
            raw_record=record
        )
    
    def _should_aggregate(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
        return (
            self.buffer_manager.should_process() or
            self.buffer_manager.is_buffer_full()
        )
    
    def _process_buffer(self) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ —Å –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π –∏ —Ç–∞–±–ª–∏—á–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –∏–∑ –±—É—Ñ–µ—Ä–∞
        records = self.buffer_manager.get_records_for_processing()
        
        if not records:
            return
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        patterns = self.pattern_detector.detect_patterns(records)
        self.stats['patterns_detected'] += len(patterns)
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è
        aggregated_records = self.aggregation_engine.aggregate(records, patterns)
        self.stats['aggregated_records'] += len(aggregated_records)
        
        # –¢–∞–±–ª–∏—á–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if self.enable_tabular_format and patterns:
            table_records = self.tabular_formatter.format_patterns_as_tables(patterns)
            aggregated_records.extend(table_records)
            self.stats['tables_generated'] += len(table_records)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ target_handler
        for agg_record in aggregated_records:
            self.target_handler.emit(agg_record)
        
        self.stats['buffer_flushes'] += 1
    
    def _schedule_flush(self) -> None:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–±—Ä–æ—Å–∞ –±—É—Ñ–µ—Ä–∞"""
        if self._flush_timer:
            self._flush_timer.cancel()
        
        self._flush_timer = threading.Timer(
            self.buffer_manager.flush_interval,
            self._force_flush
        )
        self._flush_timer.start()
    
    def _force_flush(self) -> None:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±—Ä–æ—Å –±—É—Ñ–µ—Ä–∞ –ø–æ —Ç–∞–π–º–∞—É—Ç—É"""
        with self._lock:
            self._process_buffer()
    
    def close(self) -> None:
        """–ó–∞–∫—Ä—ã—Ç–∏–µ handler —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Å–±—Ä–æ—Å–æ–º"""
        with self._lock:
            if self._flush_timer:
                self._flush_timer.cancel()
            self._process_buffer()
            self.target_handler.close()
        super().close()
    
    def toggle_aggregation(self, enabled: bool) -> None:
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –≤ runtime"""
        with self._lock:
            if not enabled and self.enabled:
                # –°–±—Ä–æ—Å –±—É—Ñ–µ—Ä–∞ –ø–µ—Ä–µ–¥ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º
                self._process_buffer()
            self.enabled = enabled
    
    def toggle_error_expansion(self, enabled: bool) -> None:
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫"""
        self.enable_error_expansion = enabled
    
    def toggle_tabular_format(self, enabled: bool) -> None:
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
        self.enable_tabular_format = enabled
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã"""
        with self._lock:
            compression_ratio = 0.0
            if self.stats['total_records'] > 0:
                processed = self.stats['total_records'] - len(self.buffer_manager.buffer)
                compression_ratio = 1 - (self.stats['aggregated_records'] / processed) if processed > 0 else 0
            
            return {
                **self.stats,
                'buffer_size': len(self.buffer_manager.buffer),
                'compression_ratio': compression_ratio,
                'enabled': self.enabled,
                'error_expansion_enabled': self.enable_error_expansion,
                'tabular_format_enabled': self.enable_tabular_format
            }

2.2 –ú–æ–¥—É–ª—å ErrorExpansionEngine (error_expansion.py)

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥ –æ—à–∏–±–æ–∫ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

import logging
from typing import List, Dict, Optional, Set
from datetime import datetime, timedelta
from dataclasses import dataclass
from collections import deque

@dataclass
class ErrorContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    error_record: LogRecord
    preceding_records: List[LogRecord]
    following_records: List[LogRecord]
    related_operations: List[LogRecord]
    error_trace: Optional[str] = None
    suggested_actions: List[str] = None

class ErrorExpansionEngine:
    """–î–≤–∏–∂–æ–∫ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –æ—à–∏–±–æ–∫"""
    
    def __init__(self, context_lines: int = 5, trace_depth: int = 10):
        self.context_lines = context_lines
        self.trace_depth = trace_depth
        
        # –ö—ç—à –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        self.operation_cache: deque[LogRecord] = deque(maxlen=100)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.error_patterns = {
            'file_not_found': {
                'keywords': ['file not found', 'no such file', 'cannot open'],
                'context_keywords': ['loading', 'opening', 'reading'],
                'suggestions': [
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞',
                    '–£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—É—Ç–∏',
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞'
                ]
            },
            'memory_error': {
                'keywords': ['memory error', 'out of memory', 'allocation failed'],
                'context_keywords': ['loading', 'processing', 'calculating'],
                'suggestions': [
                    '–£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
                    '–ó–∞–∫—Ä–æ–π—Ç–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è',
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å'
                ]
            },
            'gui_error': {
                'keywords': ['widget', 'window', 'display', 'render'],
                'context_keywords': ['updating', 'refreshing', 'drawing'],
                'suggestions': [
                    '–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ GUI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç',
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∫–Ω–∞',
                    '–û–±–Ω–æ–≤–∏—Ç–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ'
                ]
            },
            'calculation_error': {
                'keywords': ['division by zero', 'invalid value', 'nan', 'inf'],
                'context_keywords': ['calculating', 'computing', 'processing'],
                'suggestions': [
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ',
                    '–£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤',
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è'
                ]
            }
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'errors_processed': 0,
            'contexts_generated': 0,
            'traces_found': 0,
            'suggestions_provided': 0
        }
    
    def expand_error(self, error_record: LogRecord, 
                    recent_context: List[LogRecord]) -> logging.LogRecord:
        """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—à–∏–±–∫–∏
        context = self._analyze_error_context(error_record, recent_context)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        expanded_message = self._generate_expanded_message(context)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞
        expanded_record = self._create_expanded_record(error_record, expanded_message, context)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats['errors_processed'] += 1
        if context.preceding_records or context.following_records:
            self.stats['contexts_generated'] += 1
        if context.error_trace:
            self.stats['traces_found'] += 1
        if context.suggested_actions:
            self.stats['suggestions_provided'] += 1
        
        return expanded_record
    
    def _analyze_error_context(self, error_record: LogRecord, 
                              recent_context: List[LogRecord]) -> ErrorContext:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—à–∏–±–∫–∏"""
        
        # –ü–æ–∏—Å–∫ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
        preceding_records = self._find_preceding_context(error_record, recent_context)
        
        # –ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        related_operations = self._find_related_operations(error_record, recent_context)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        error_type = self._classify_error(error_record)
        suggestions = self._generate_suggestions(error_type, error_record)
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
        error_trace = self._extract_error_trace(error_record, recent_context)
        
        return ErrorContext(
            error_record=error_record,
            preceding_records=preceding_records,
            following_records=[],  # –í —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –Ω–µ—Ç
            related_operations=related_operations,
            error_trace=error_trace,
            suggested_actions=suggestions
        )
    
    def _find_preceding_context(self, error_record: LogRecord, 
                               recent_context: List[LogRecord]) -> List[LogRecord]:
        """–ü–æ–∏—Å–∫ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if not recent_context:
            return []
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–µ–π –¥–æ –æ—à–∏–±–∫–∏
        preceding = [
            record for record in recent_context 
            if record.timestamp < error_record.timestamp
        ]
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        preceding.sort(key=lambda x: x.timestamp, reverse=True)
        return preceding[:self.context_lines]
    
    def _find_related_operations(self, error_record: LogRecord, 
                                recent_context: List[LogRecord]) -> List[LogRecord]:
        """–ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
        related = []
        
        # –ü–æ–∏—Å–∫ –æ–ø–µ—Ä–∞—Ü–∏–π –≤ —Ç–æ–º –∂–µ —Ñ–∞–π–ª–µ
        same_file_ops = [
            record for record in recent_context
            if (record.filename == error_record.filename and 
                abs((record.timestamp - error_record.timestamp).total_seconds()) < 5)
        ]
        related.extend(same_file_ops)
        
        # –ü–æ–∏—Å–∫ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ø–æ—Ö–æ–∂–∏–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        error_keywords = self._extract_keywords(error_record.message)
        for record in recent_context:
            record_keywords = self._extract_keywords(record.message)
            if len(error_keywords.intersection(record_keywords)) >= 2:
                related.append(record)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        seen = set()
        unique_related = []
        for record in related:
            record_id = (record.timestamp, record.message)
            if record_id not in seen:
                seen.add(record_id)
                unique_related.append(record)
        
        unique_related.sort(key=lambda x: x.timestamp)
        return unique_related[:5]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
    
    def _classify_error(self, error_record: LogRecord) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏"""
        message_lower = error_record.message.lower()
        
        for error_type, pattern in self.error_patterns.items():
            if any(keyword in message_lower for keyword in pattern['keywords']):
                return error_type
        
        return 'unknown'
    
    def _generate_suggestions(self, error_type: str, error_record: LogRecord) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é –æ—à–∏–±–∫–∏"""
        if error_type in self.error_patterns:
            base_suggestions = self.error_patterns[error_type]['suggestions'].copy()
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            if error_record.filename:
                base_suggestions.append(f'–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–¥ –≤ —Ñ–∞–π–ª–µ {error_record.filename}:{error_record.line_number}')
            
            return base_suggestions
        
        return ['–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏']
    
    def _extract_error_trace(self, error_record: LogRecord, 
                            recent_context: List[LogRecord]) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –æ—à–∏–±–∫–∏"""
        # –ü–æ–∏—Å–∫ –∑–∞–ø–∏—Å–µ–π —Å —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–æ–π –≤ –Ω–µ–¥–∞–≤–Ω–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        trace_records = []
        
        for record in recent_context:
            if any(keyword in record.message.lower() 
                   for keyword in ['traceback', 'stack trace', 'exception']):
                trace_records.append(record)
        
        if trace_records:
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
            trace_lines = []
            for record in trace_records[-self.trace_depth:]:
                trace_lines.append(f"[{record.timestamp.strftime('%H:%M:%S')}] {record.message}")
            
            return '\n'.join(trace_lines)
        
        return None
    
    def _extract_keywords(self, message: str) -> Set[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é NLP)
        words = message.lower().split()
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ (–¥–ª–∏–Ω–∞ > 3, –Ω–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞)
        keywords = {
            word for word in words 
            if len(word) > 3 and word not in {'with', 'from', 'this', 'that', 'have', 'been'}
        }
        return keywords
    
    def _generate_expanded_message(self, context: ErrorContext) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—à–∏–±–∫–∏"""
        lines = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—à–∏–±–∫–∏
        lines.append("=" * 80)
        lines.append(f"üö® DETAILED ERROR ANALYSIS - {context.error_record.level}")
        lines.append("=" * 80)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –æ—à–∏–±–∫–∞
        lines.append(f"üìç Location: {context.error_record.filename}:{context.error_record.line_number}")
        lines.append(f"‚è∞ Time: {context.error_record.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"üí¨ Message: {context.error_record.message}")
        lines.append("")
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        if context.preceding_records:
            lines.append("üìã PRECEDING CONTEXT:")
            lines.append("-" * 40)
            for i, record in enumerate(context.preceding_records[-5:], 1):
                time_diff = (context.error_record.timestamp - record.timestamp).total_seconds()
                lines.append(f"  {i}. [{record.level}] {record.message} ({time_diff:.1f}s ago)")
            lines.append("")
        
        # –°–≤—è–∑–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
        if context.related_operations:
            lines.append("üîó RELATED OPERATIONS:")
            lines.append("-" * 40)
            for i, record in enumerate(context.related_operations, 1):
                lines.append(f"  {i}. [{record.level}] {record.filename}:{record.line_number} - {record.message}")
            lines.append("")
        
        # –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞
        if context.error_trace:
            lines.append("üìä ERROR TRACE:")
            lines.append("-" * 40)
            lines.append(context.error_trace)
            lines.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if context.suggested_actions:
            lines.append("üí° SUGGESTED ACTIONS:")
            lines.append("-" * 40)
            for i, suggestion in enumerate(context.suggested_actions, 1):
                lines.append(f"  {i}. {suggestion}")
            lines.append("")
        
        lines.append("=" * 80)
        
        return '\n'.join(lines)
    
    def _create_expanded_record(self, original_record: LogRecord, 
                               expanded_message: str, 
                               context: ErrorContext) -> logging.LogRecord:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"""
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ LogRecord —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        expanded_record = logging.LogRecord(
            name=f"solid_state_kinetics.error_expanded",
            level=getattr(logging, original_record.level),
            pathname=original_record.filename,
            lineno=original_record.line_number,
            msg=expanded_message,
            args=(),
            exc_info=None
        )
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
        expanded_record.created = original_record.timestamp.timestamp()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        expanded_record.error_context = context
        expanded_record.original_message = original_record.message
        expanded_record.expansion_type = 'detailed_error_analysis'
        
        return expanded_record
    
    def get_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –¥–≤–∏–∂–∫–∞"""
        return self.stats.copy()

2.3 –ú–æ–¥—É–ª—å TabularFormatter (tabular_formatter.py)

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –¢–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
from collections import defaultdict
import json

@dataclass
class TableData:
    """–î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
    title: str
    headers: List[str]
    rows: List[List[str]]
    summary: Optional[str] = None
    table_type: str = 'generic'

class TabularFormatter:
    """–§–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–æ–≥–æ–≤"""
    
    def __init__(self, max_table_width: int = 120, max_rows_per_table: int = 20):
        self.max_table_width = max_table_width
        self.max_rows_per_table = max_rows_per_table
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'tables_created': 0,
            'rows_formatted': 0,
            'patterns_processed': 0
        }
    
    def format_patterns_as_tables(self, patterns: List['PatternGroup']) -> List[logging.LogRecord]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü"""
        table_records = []
        
        for pattern in patterns:
            table_data = self._create_table_for_pattern(pattern)
            if table_data:
                table_record = self._create_table_record(table_data, pattern)
                table_records.append(table_record)
                
                self.stats['tables_created'] += 1
                self.stats['rows_formatted'] += len(table_data.rows)
        
        self.stats['patterns_processed'] += len(patterns)
        return table_records
    
    def _create_table_for_pattern(self, pattern: 'PatternGroup') -> Optional[TableData]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        
        if pattern.pattern_type == "plot_lines_addition":
            return self._create_plot_lines_table(pattern)
        
        elif pattern.pattern_type == "cascade_component_initialization":
            return self._create_initialization_table(pattern)
        
        elif pattern.pattern_type == "request_response_cycle":
            return self._create_request_response_table(pattern)
        
        elif pattern.pattern_type == "file_operations":
            return self._create_file_operations_table(pattern)
        
        elif pattern.pattern_type == "gui_updates":
            return self._create_gui_updates_table(pattern)
        
        else:
            return self._create_generic_table(pattern)
    
    def _create_plot_lines_table(self, pattern: 'PatternGroup') -> TableData:
        """–¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏–Ω–∏–π –Ω–∞ –≥—Ä–∞—Ñ–∏–∫"""
        headers = ["#", "Line Name", "Time", "Duration (ms)", "Status"]
        rows = []
        
        start_time = pattern.start_time
        
        for i, record in enumerate(pattern.records, 1):
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–∏–Ω–∏–∏
            line_name = "Unknown"
            if "'" in record.message:
                try:
                    line_name = record.message.split("'")[1]
                except IndexError:
                    line_name = "Parse Error"
            
            # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç –Ω–∞—á–∞–ª–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏
            time_offset = (record.timestamp - start_time).total_seconds() * 1000
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
            status = "‚úÖ Success" if record.level == "INFO" else f"‚ö†Ô∏è {record.level}"
            
            rows.append([
                str(i),
                line_name[:30],  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
                f"+{time_offset:.1f}ms",
                f"{time_offset:.1f}",
                status
            ])
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫
        if len(rows) > self.max_rows_per_table:
            displayed_rows = rows[:self.max_rows_per_table-1]
            displayed_rows.append([
                "...", 
                f"({len(rows) - self.max_rows_per_table + 1} more lines)", 
                "...", 
                "...", 
                "..."
            ])
            rows = displayed_rows
        
        duration = pattern.duration.total_seconds() * 1000
        summary = f"Total: {pattern.count} lines added in {duration:.1f}ms (avg: {duration/pattern.count:.1f}ms per line)"
        
        return TableData(
            title=f"üìä Plot Lines Addition Summary",
            headers=headers,
            rows=rows,
            summary=summary,
            table_type="plot_lines"
        )
    
    def _create_initialization_table(self, pattern: 'PatternGroup') -> TableData:
        """–¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        headers = ["Step", "Component", "Time", "Duration (ms)", "Status"]
        rows = []
        
        start_time = pattern.start_time
        prev_time = start_time
        
        for i, record in enumerate(pattern.records, 1):
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
            component_name = "Unknown Component"
            if "Initializing" in record.message:
                component_name = record.message.split("Initializing")[-1].strip()
            
            # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
            step_duration = (record.timestamp - prev_time).total_seconds() * 1000
            total_time = (record.timestamp - start_time).total_seconds() * 1000
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
            status = "‚úÖ OK" if record.level == "INFO" else f"‚ö†Ô∏è {record.level}"
            
            rows.append([
                str(i),
                component_name[:25],
                f"+{total_time:.1f}ms",
                f"{step_duration:.1f}",
                status
            ])
            
            prev_time = record.timestamp
        
        total_duration = pattern.duration.total_seconds() * 1000
        summary = f"Initialization cascade: {pattern.count} components in {total_duration:.1f}ms"
        
        return TableData(
            title=f"üîß Component Initialization Cascade",
            headers=headers,
            rows=rows,
            summary=summary,
            table_type="initialization"
        )
    
    def _create_request_response_table(self, pattern: 'PatternGroup') -> TableData:
        """–¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ü–∏–∫–ª–æ–≤ –∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
        headers = ["#", "Operation", "Time", "Duration (ms)", "Status"]
        rows = []
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π –ø–æ –ø–∞—Ä–∞–º –∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
        request_response_pairs = self._group_request_response_pairs(pattern.records)
        
        for i, (request, response) in enumerate(request_response_pairs, 1):
            if response:
                duration = (response.timestamp - request.timestamp).total_seconds() * 1000
                status = "‚úÖ Complete" if response.level == "INFO" else f"‚ö†Ô∏è {response.level}"
            else:
                duration = 0
                status = "‚è≥ Pending"
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏
            operation = self._extract_operation_type(request.message)
            
            rows.append([
                str(i),
                operation[:30],
                request.timestamp.strftime("%H:%M:%S.%f")[:-3],
                f"{duration:.1f}" if duration > 0 else "N/A",
                status
            ])
        
        avg_duration = sum(
            (resp.timestamp - req.timestamp).total_seconds() * 1000 
            for req, resp in request_response_pairs if resp
        ) / len([p for p in request_response_pairs if p[1]])
        
        summary = f"Request-Response cycles: {len(request_response_pairs)} operations, avg: {avg_duration:.1f}ms"
        
        return TableData(
            title=f"üîÑ Request-Response Cycles",
            headers=headers,
            rows=rows,
            summary=summary,
            table_type="request_response"
        )
    
    def _create_file_operations_table(self, pattern: 'PatternGroup') -> TableData:
        """–¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
        headers = ["#", "Operation", "File", "Time", "Status"]
        rows = []
        
        for i, record in enumerate(pattern.records, 1):
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ —Ñ–∞–π–ª–∞
            operation_type = self._extract_file_operation_type(record.message)
            file_name = self._extract_file_name(record.message)
            
            status = "‚úÖ Success" if record.level == "INFO" else f"‚ö†Ô∏è {record.level}"
            
            rows.append([
                str(i),
                operation_type,
                file_name[:25],
                record.timestamp.strftime("%H:%M:%S.%f")[:-3],
                status
            ])
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π
        operation_counts = defaultdict(int)
        for record in pattern.records:
            op_type = self._extract_file_operation_type(record.message)
            operation_counts[op_type] += 1
        
        summary = f"File operations: {', '.join(f'{op}: {count}' for op, count in operation_counts.items())}"
        
        return TableData(
            title=f"üìÅ File Operations Summary",
            headers=headers,
            rows=rows,
            summary=summary,
            table_type="file_operations"
        )
    
    def _create_gui_updates_table(self, pattern: 'PatternGroup') -> TableData:
        """–¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π GUI"""
        headers = ["#", "Component", "Update Type", "Time", "Duration (ms)"]
        rows = []
        
        start_time = pattern.start_time
        
        for i, record in enumerate(pattern.records, 1):
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –∏ —Ç–∏–ø–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            component = self._extract_gui_component(record.message)
            update_type = self._extract_update_type(record.message)
            
            time_offset = (record.timestamp - start_time).total_seconds() * 1000
            
            rows.append([
                str(i),
                component[:20],
                update_type[:15],
                f"+{time_offset:.1f}ms",
                f"{time_offset:.1f}"
            ])
        
        total_duration = pattern.duration.total_seconds() * 1000
        summary = f"GUI updates: {pattern.count} operations in {total_duration:.1f}ms"
        
        return TableData(
            title=f"üñ•Ô∏è GUI Updates Batch",
            headers=headers,
            rows=rows,
            summary=summary,
            table_type="gui_updates"
        )
    
    def _create_generic_table(self, pattern: 'PatternGroup') -> TableData:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        headers = ["#", "Level", "Message", "Time", "File:Line"]
        rows = []
        
        for i, record in enumerate(pattern.records, 1):
            rows.append([
                str(i),
                record.level,
                record.message[:40] + "..." if len(record.message) > 40 else record.message,
                record.timestamp.strftime("%H:%M:%S.%f")[:-3],
                f"{record.filename}:{record.line_number}"
            ])
        
        summary = f"Pattern: {pattern.pattern_type}, {pattern.count} records"
        
        return TableData(
            title=f"üìã Generic Pattern: {pattern.pattern_type}",
            headers=headers,
            rows=rows,
            summary=summary,
            table_type="generic"
        )
    
    def _create_table_record(self, table_data: TableData, pattern: 'PatternGroup') -> logging.LogRecord:
        """–°–æ–∑–¥–∞–Ω–∏–µ LogRecord —Å —Ç–∞–±–ª–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ ASCII
        ascii_table = self._format_ascii_table(table_data)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞
        table_record = logging.LogRecord(
            name="solid_state_kinetics.table",
            level=logging.INFO,
            pathname="tabular_formatter",
            lineno=0,
            msg=ascii_table,
            args=(),
            exc_info=None
        )
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        table_record.created = pattern.start_time.timestamp()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        table_record.table_data = table_data
        table_record.pattern_type = pattern.pattern_type
        table_record.table_type = table_data.table_type
        
        return table_record
    
    def _format_ascii_table(self, table_data: TableData) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ ASCII —Ñ–æ—Ä–º–∞—Ç"""
        lines = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        lines.append("")
        lines.append("‚îå" + "‚îÄ" * (self.max_table_width - 2) + "‚îê")
        title_line = f"‚îÇ {table_data.title:<{self.max_table_width - 4}} ‚îÇ"
        lines.append(title_line)
        lines.append("‚îú" + "‚îÄ" * (self.max_table_width - 2) + "‚î§")
        
        # –†–∞—Å—á–µ—Ç —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
        col_widths = self._calculate_column_widths(table_data)
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        header_line = "‚îÇ " + " ‚îÇ ".join(
            header.ljust(width) for header, width in zip(table_data.headers, col_widths)
        ) + " ‚îÇ"
        lines.append(header_line)
        
        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        separator = "‚îú" + "‚îº".join("‚îÄ" * (width + 2) for width in col_widths) + "‚î§"
        lines.append(separator)
        
        # –°—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        for row in table_data.rows:
            row_line = "‚îÇ " + " ‚îÇ ".join(
                str(cell).ljust(width) for cell, width in zip(row, col_widths)
            ) + " ‚îÇ"
            lines.append(row_line)
        
        # –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
        lines.append("‚îî" + "‚îÄ" * (self.max_table_width - 2) + "‚îò")
        
        # –°–≤–æ–¥–∫–∞
        if table_data.summary:
            lines.append(f"üìä {table_data.summary}")
        
        lines.append("")
        
        return '\n'.join(lines)
    
    def _calculate_column_widths(self, table_data: TableData) -> List[int]:
        """–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫"""
        if not table_data.rows:
            return [10] * len(table_data.headers)
        
        # –ù–∞—á–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        col_widths = [len(header) for header in table_data.headers]
        
        # –£—á–µ—Ç —à–∏—Ä–∏–Ω—ã –¥–∞–Ω–Ω—ã—Ö
        for row in table_data.rows:
            for i, cell in enumerate(row):
                if i < len(col_widths):
                    col_widths[i] = max(col_widths[i], len(str(cell)))
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω—ã
        max_col_width = 30
        col_widths = [min(width, max_col_width) for width in col_widths]
        
        # –ü–æ–¥–≥–æ–Ω–∫–∞ –ø–æ–¥ –æ–±—â—É—é —à–∏—Ä–∏–Ω—É —Ç–∞–±–ª–∏—Ü—ã
        total_width = sum(col_widths) + len(col_widths) * 3 + 1  # –£—á–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
        if total_width > self.max_table_width:
            # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ
            scale_factor = (self.max_table_width - len(col_widths) * 3 - 1) / sum(col_widths)
            col_widths = [max(5, int(width * scale_factor)) for width in col_widths]
        
        return col_widths
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    
    def _group_request_response_pairs(self, records: List['LogRecord']) -> List[tuple]:
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞—Ä—ã –∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
        pairs = []
        pending_requests = []
        
        for record in records:
            message_lower = record.message.lower()
            
            if any(keyword in message_lower for keyword in ['request', 'emitting', 'handle']):
                pending_requests.append(record)
            elif any(keyword in message_lower for keyword in ['response', 'received', 'completed']):
                if pending_requests:
                    request = pending_requests.pop(0)
                    pairs.append((request, record))
                else:
                    pairs.append((record, None))
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ—Å–ø–∞—Ä–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        for request in pending_requests:
            pairs.append((request, None))
        
        return pairs
    
    def _extract_operation_type(self, message: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        message_lower = message.lower()
        
        if 'file' in message_lower:
            return 'File Operation'
        elif 'gui' in message_lower or 'window' in message_lower:
            return 'GUI Operation'
        elif 'calculation' in message_lower or 'compute' in message_lower:
            return 'Calculation'
        elif 'network' in message_lower or 'request' in message_lower:
            return 'Network'
        else:
            return 'General'
    
    def _extract_file_operation_type(self, message: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        message_lower = message.lower()
        
        if 'loading' in message_lower or 'load' in message_lower:
            return 'Load'
        elif 'saving' in message_lower or 'save' in message_lower:
            return 'Save'
        elif 'opening' in message_lower or 'open' in message_lower:
            return 'Open'
        elif 'closing' in message_lower or 'close' in message_lower:
            return 'Close'
        else:
            return 'Other'
    
    def _extract_file_name(self, message: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ - –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        words = message.split()
        for word in words:
            if '.' in word and len(word) > 3:
                return word
        return 'Unknown'
    
    def _extract_gui_component(self, message: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ GUI"""
        message_lower = message.lower()
        
        if 'window' in message_lower:
            return 'Window'
        elif 'button' in message_lower:
            return 'Button'
        elif 'plot' in message_lower or 'graph' in message_lower:
            return 'Plot'
        elif 'menu' in message_lower:
            return 'Menu'
        elif 'dialog' in message_lower:
            return 'Dialog'
        else:
            return 'Component'
    
    def _extract_update_type(self, message: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        message_lower = message.lower()
        
        if 'refresh' in message_lower:
            return 'Refresh'
        elif 'redraw' in message_lower or 'paint' in message_lower:
            return 'Redraw'
        elif 'update' in message_lower:
            return 'Update'
        else:
            return 'Change'
    
    def get_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä–∞"""
        return self.stats.copy()

2.4 –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å BufferManager (buffer_manager.py)

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—É—Ñ–µ—Ä–∞–º–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—à–∏–±–æ–∫

from collections import deque
from datetime import datetime, timedelta
from typing import List, Optional
import threading

class BufferManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–µ–π –ª–æ–≥–æ–≤ –≤ –ø–∞–º—è—Ç–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫–Ω–∞–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –æ—à–∏–±–æ–∫"""
    
    def __init__(self, max_size: int = 1000, flush_interval: float = 2.0, 
                 context_size: int = 20):
        self.max_size = max_size
        self.flush_interval = flush_interval
        self.context_size = context_size  # –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—à–∏–±–æ–∫
        
        self.buffer: deque[LogRecord] = deque(maxlen=max_size)
        self.context_buffer: deque[LogRecord] = deque(maxlen=context_size)  # –û—Ç–¥–µ–ª—å–Ω—ã–π –±—É—Ñ–µ—Ä –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.last_flush = datetime.now()
        self._lock = threading.RLock()
    
    def add_record(self, record: LogRecord) -> None:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –±—É—Ñ–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        with self._lock:
            self.buffer.append(record)
            self.context_buffer.append(record)  # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –±—É—Ñ–µ—Ä
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
            self._cleanup_old_records()
    
    def get_recent_context(self, max_records: int = None) -> List[LogRecord]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–¥–∞–≤–Ω–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫"""
        with self._lock:
            max_records = max_records or self.context_size
            return list(self.context_buffer)[-max_records:]
    
    def should_process(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±—É—Ñ–µ—Ä–∞"""
        with self._lock:
            time_threshold = datetime.now() - timedelta(seconds=self.flush_interval)
            return (
                len(self.buffer) >= 10 or  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                self.last_flush < time_threshold
            )
    
    def is_buffer_full(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ –±—É—Ñ–µ—Ä–∞"""
        return len(self.buffer) >= self.max_size * 0.8  # 80% –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
    
    def get_records_for_processing(self) -> List[LogRecord]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –æ—á–∏—Å—Ç–∫–æ–π –±—É—Ñ–µ—Ä–∞"""
        with self._lock:
            if not self.buffer:
                return []
            
            # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π
            records = list(self.buffer)
            
            # –û—á–∏—Å—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞ (–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –±—É—Ñ–µ—Ä –æ—Å—Ç–∞–µ—Ç—Å—è)
            self.buffer.clear()
            self.last_flush = datetime.now()
            
            return records
    
    def _cleanup_old_records(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (—Å—Ç–∞—Ä—à–µ 30 —Å–µ–∫—É–Ω–¥)"""
        if not self.buffer:
            return
        
        cutoff_time = datetime.now() - timedelta(seconds=30)
        
        # –û—á–∏—Å—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞
        while self.buffer and self.buffer[0].timestamp < cutoff_time:
            self.buffer.popleft()
        
        # –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞ (–±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥)
        context_cutoff = datetime.now() - timedelta(seconds=10)
        while self.context_buffer and self.context_buffer[0].timestamp < context_cutoff:
            self.context_buffer.popleft()
    
    def get_buffer_info(self) -> dict:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –±—É—Ñ–µ—Ä–∞"""
        with self._lock:
            oldest_record = self.buffer[0].timestamp if self.buffer else None
            newest_record = self.buffer[-1].timestamp if self.buffer else None
            
            return {
                'size': len(self.buffer),
                'max_size': self.max_size,
                'context_size': len(self.context_buffer),
                'max_context_size': self.context_size,
                'oldest_record': oldest_record,
                'newest_record': newest_record,
                'last_flush': self.last_flush
            }

2.5 –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å PatternDetector (pattern_detector.py)

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è

from typing import List, Dict, Set
from datetime import timedelta
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class PatternGroup:
    pattern_type: str
    records: List[LogRecord]
    start_time: datetime
    end_time: datetime
    metadata: Dict[str, Any] = None  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    
    @property
    def duration(self) -> timedelta:
        return self.end_time - self.start_time
    
    @property
    def count(self) -> int:
        return len(self.records)

class PatternDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –ø–æ—Ç–æ–∫–µ –ª–æ–≥–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
    
    def __init__(self, min_entries: int = 3, time_window_seconds: int = 5):
        self.min_entries = min_entries
        self.time_window = timedelta(seconds=time_window_seconds)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        self.cascade_state: Dict[str, List[LogRecord]] = defaultdict(list)
        self.cascade_timeouts: Dict[str, datetime] = {}
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ª—É—á—à–µ–≥–æ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        self.enhanced_patterns = {
            'plot_lines_addition': {
                'keywords': ['adding a new line', 'plot line', 'line added'],
                'context_keywords': ['plot', 'graph', 'chart'],
                'table_suitable': True,
                'priority': 'high'
            },
            'cascade_component_initialization': {
                'keywords': ['initializing', 'init', 'startup'],
                'context_keywords': ['component', 'module', 'system'],
                'table_suitable': True,
                'priority': 'high'
            },
            'request_response_cycle': {
                'keywords': ['handle_request', 'emitting request', 'response received', 'request completed'],
                'context_keywords': ['http', 'api', 'service'],
                'table_suitable': True,
                'priority': 'medium'
            },
            'file_operations': {
                'keywords': ['loading', 'saving', 'selected file', 'file opened', 'file closed'],
                'context_keywords': ['file', 'path', 'directory'],
                'table_suitable': True,
                'priority': 'medium'
            },
            'gui_updates': {
                'keywords': ['updating', 'refreshing', 'redraw', 'paint', 'render'],
                'context_keywords': ['gui', 'window', 'widget'],
                'table_suitable': True,
                'priority': 'low'
            },
            'error_sequences': {
                'keywords': ['error', 'exception', 'failed', 'warning'],
                'context_keywords': ['traceback', 'stack', 'debug'],
                'table_suitable': False,  # –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
                'priority': 'critical'
            }
        }
    
    def detect_patterns(self, records: List[LogRecord]) -> List[PatternGroup]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —Å–ø–∏—Å–∫–µ –∑–∞–ø–∏—Å–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if not records:
            return []
        
        patterns = []
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        sorted_records = sorted(records, key=lambda x: x.timestamp)
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        pattern_groups = self._group_by_enhanced_patterns(sorted_records)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
        for pattern_type, group_records in pattern_groups.items():
            pattern_config = self.enhanced_patterns.get(pattern_type, {})
            
            if pattern_type.startswith('cascade_'):
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
                cascade_patterns = self._process_cascade_pattern(pattern_type, group_records)
                patterns.extend(cascade_patterns)
            else:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                time_groups = self._split_by_time_window(group_records)
                for time_group in time_groups:
                    if len(time_group) >= self.min_entries:
                        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                        metadata = self._generate_pattern_metadata(pattern_type, time_group)
                        
                        patterns.append(PatternGroup(
                            pattern_type=pattern_type,
                            records=time_group,
                            start_time=time_group[0].timestamp,
                            end_time=time_group[-1].timestamp,
                            metadata=metadata
                        ))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ –≤—Ä–µ–º–µ–Ω–∏
        patterns.sort(key=lambda p: (
            self._get_pattern_priority(p.pattern_type),
            p.start_time
        ))
        
        return patterns
    
    def _group_by_enhanced_patterns(self, records: List[LogRecord]) -> Dict[str, List[LogRecord]]:
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Ç–∏–ø–∞–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        groups = defaultdict(list)
        
        for record in records:
            pattern_key = self._get_enhanced_pattern_key(record)
            groups[pattern_key].append(record)
        
        return groups
    
    def _get_enhanced_pattern_key(self, record: LogRecord) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ —Å —É—á–µ—Ç–æ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        message = record.message.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        for pattern_type, config in self.enhanced_patterns.items():
            if any(keyword in message for keyword in config['keywords']):
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                if config.get('context_keywords'):
                    if any(ctx_keyword in message for ctx_keyword in config['context_keywords']):
                        return pattern_type
                else:
                    return pattern_type
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        if "initializing" in message:
            return "cascade_component_initialization"
        
        return "other"
    
    def _generate_pattern_metadata(self, pattern_type: str, records: List[LogRecord]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        metadata = {
            'table_suitable': self.enhanced_patterns.get(pattern_type, {}).get('table_suitable', False),
            'priority': self.enhanced_patterns.get(pattern_type, {}).get('priority', 'low'),
            'record_count': len(records),
            'duration_ms': (records[-1].timestamp - records[0].timestamp).total_seconds() * 1000,
            'files_involved': list(set(record.filename for record in records)),
            'levels_distribution': self._calculate_level_distribution(records)
        }
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        if pattern_type == "plot_lines_addition":
            metadata.update(self._extract_plot_lines_metadata(records))
        elif pattern_type == "file_operations":
            metadata.update(self._extract_file_operations_metadata(records))
        elif pattern_type == "request_response_cycle":
            metadata.update(self._extract_request_response_metadata(records))
        
        return metadata
    
    def _extract_plot_lines_metadata(self, records: List[LogRecord]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ª–∏–Ω–∏—è–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞"""
        line_names = []
        for record in records:
            if "'" in record.message:
                try:
                    line_name = record.message.split("'")[1]
                    line_names.append(line_name)
                except IndexError:
                    pass
        
        return {
            'line_names': line_names,
            'unique_lines': len(set(line_names)),
            'avg_time_per_line': (records[-1].timestamp - records[0].timestamp).total_seconds() * 1000 / len(records) if records else 0
        }
    
    def _extract_file_operations_metadata(self, records: List[LogRecord]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
        operations = defaultdict(int)
        files = set()
        
        for record in records:
            message_lower = record.message.lower()
            
            if 'loading' in message_lower:
                operations['load'] += 1
            elif 'saving' in message_lower:
                operations['save'] += 1
            elif 'opening' in message_lower:
                operations['open'] += 1
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            words = record.message.split()
            for word in words:
                if '.' in word and len(word) > 3:
                    files.add(word)
        
        return {
            'operation_types': dict(operations),
            'files_affected': list(files),
            'total_operations': sum(operations.values())
        }
    
    def _extract_request_response_metadata(self, records: List[LogRecord]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ü–∏–∫–ª–æ–≤ –∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
        requests = 0
        responses = 0
        
        for record in records:
            message_lower = record.message.lower()
            if any(keyword in message_lower for keyword in ['request', 'emitting']):
                requests += 1
            elif any(keyword in message_lower for keyword in ['response', 'received']):
                responses += 1
        
        return {
            'requests_count': requests,
            'responses_count': responses,
            'completion_ratio': responses / requests if requests > 0 else 0
        }
    
    def _calculate_level_distribution(self, records: List[LogRecord]) -> Dict[str, int]:
        """–†–∞—Å—á–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        distribution = defaultdict(int)
        for record in records:
            distribution[record.level] += 1
        return dict(distribution)
    
    def _get_pattern_priority(self, pattern_type: str) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏"""
        priority_map = {
            'critical': 0,
            'high': 1,
            'medium': 2,
            'low': 3
        }
        
        priority = self.enhanced_patterns.get(pattern_type, {}).get('priority', 'low')
        return priority_map.get(priority, 3)
    
    def _process_cascade_pattern(self, pattern_type: str, records: List[LogRecord]) -> List[PatternGroup]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        patterns = []
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Å–∫–∞–¥–Ω—ã–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º
        cascade_groups = self._detect_cascade_sequences(records)
        
        for cascade_group in cascade_groups:
            if len(cascade_group) >= self.min_entries:
                metadata = self._generate_cascade_metadata(cascade_group)
                
                patterns.append(PatternGroup(
                    pattern_type=pattern_type,
                    records=cascade_group,
                    start_time=cascade_group[0].timestamp,
                    end_time=cascade_group[-1].timestamp,
                    metadata=metadata
                ))
        
        return patterns
    
    def _generate_cascade_metadata(self, records: List[LogRecord]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
        components = []
        for record in records:
            if "Initializing" in record.message:
                comp_name = record.message.split("Initializing")[-1].strip()
                components.append(comp_name)
        
        return {
            'table_suitable': True,
            'priority': 'high',
            'components': components,
            'cascade_depth': len(components),
            'avg_step_time': (records[-1].timestamp - records[0].timestamp).total_seconds() * 1000 / len(records) if records else 0
        }
    
    def _detect_cascade_sequences(self, records: List[LogRecord]) -> List[List[LogRecord]]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π"""
        sequences = []
        current_sequence = []
        
        for record in records:
            if not current_sequence:
                current_sequence = [record]
            else:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏
                time_diff = record.timestamp - current_sequence[-1].timestamp
                if time_diff <= timedelta(seconds=1):  # –ö–∞—Å–∫–∞–¥ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 1 —Å–µ–∫—É–Ω–¥—ã
                    current_sequence.append(record)
                else:
                    if len(current_sequence) >= self.min_entries:
                        sequences.append(current_sequence)
                    current_sequence = [record]
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if len(current_sequence) >= self.min_entries:
            sequences.append(current_sequence)
        
        return sequences
    
    def _split_by_time_window(self, records: List[LogRecord]) -> List[List[LogRecord]]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫–Ω–∞–º"""
        if not records:
            return []
        
        groups = []
        current_group = [records[0]]
        
        for record in records[1:]:
            if record.timestamp - current_group[-1].timestamp <= self.time_window:
                current_group.append(record)
            else:
                groups.append(current_group)
                current_group = [record]
        
        groups.append(current_group)
        return groups

2.6 –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å AggregationEngine (aggregation_engine.py)

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –î–≤–∏–∂–æ–∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

import logging
from typing import List, Union
from datetime import datetime

class AggregatedLogRecord(logging.LogRecord):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π LogRecord –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π"""
    
    def __init__(self, summary: str, original_records: List[LogRecord], 
                 pattern_type: str, start_time: datetime, end_time: datetime,
                 metadata: dict = None):
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ LogRecord
        super().__init__(
            name="solid_state_kinetics.aggregated",
            level=logging.INFO,
            pathname="aggregated",
            lineno=0,
            msg=summary,
            args=(),
            exc_info=None
        )
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        self.original_records = original_records
        self.pattern_type = pattern_type
        self.start_time = start_time
        self.end_time = end_time
        self.aggregated_count = len(original_records)
        self.duration = (end_time - start_time).total_seconds()
        self.metadata = metadata or {}
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
        self.created = start_time.timestamp()

class AggregationEngine:
    """–î–≤–∏–∂–æ–∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.aggregation_stats = {
            'total_processed': 0,
            'total_aggregated': 0,
            'patterns_processed': 0,
            'table_suitable_patterns': 0
        }
    
    def aggregate(self, records: List[LogRecord], 
                 patterns: List[PatternGroup]) -> List[logging.LogRecord]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞–ø–∏—Å–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if not records:
            return []
        
        result = []
        processed_record_ids = set()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        for pattern in patterns:
            aggregated_record = self._create_enhanced_aggregated_record(pattern)
            result.append(aggregated_record)
            
            # –û—Ç–º–µ—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
            for record in pattern.records:
                processed_record_ids.add(id(record))
            
            self.aggregation_stats['patterns_processed'] += 1
            
            # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            if pattern.metadata and pattern.metadata.get('table_suitable', False):
                self.aggregation_stats['table_suitable_patterns'] += 1
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        for record in records:
            if id(record) not in processed_record_ids:
                result.append(record.raw_record)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        result.sort(key=lambda x: x.created)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.aggregation_stats['total_processed'] += len(records)
        self.aggregation_stats['total_aggregated'] += len(patterns)
        
        return result
    
    def _create_enhanced_aggregated_record(self, pattern: PatternGroup) -> AggregatedLogRecord:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        summary = self._generate_enhanced_summary(pattern)
        
        return AggregatedLogRecord(
            summary=summary,
            original_records=pattern.records,
            pattern_type=pattern.pattern_type,
            start_time=pattern.start_time,
            end_time=pattern.end_time,
            metadata=pattern.metadata
        )
    
    def _generate_enhanced_summary(self, pattern: PatternGroup) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        duration = pattern.duration.total_seconds()
        metadata = pattern.metadata or {}
        
        if pattern.pattern_type == "plot_lines_addition":
            line_names = metadata.get('line_names', [])
            unique_lines = metadata.get('unique_lines', len(line_names))
            avg_time = metadata.get('avg_time_per_line', 0)
            
            lines_preview = ', '.join(line_names[:3])
            if len(line_names) > 3:
                lines_preview += f"... (+{len(line_names)-3} more)"
            
            return (f"üìä AGGREGATED: Added {unique_lines} plot lines [{lines_preview}] "
                   f"({duration:.1f}s, avg: {avg_time:.1f}ms per line)")
        
        elif pattern.pattern_type == "cascade_component_initialization":
            components = metadata.get('components', [])
            cascade_depth = metadata.get('cascade_depth', len(components))
            avg_step_time = metadata.get('avg_step_time', 0)
            
            comp_chain = " ‚Üí ".join(components[:5])
            if len(components) > 5:
                comp_chain += "..."
            
            return (f"üîß AGGREGATED: Component initialization cascade "
                   f"[{comp_chain}] ({cascade_depth} steps, {duration:.1f}s, "
                   f"avg: {avg_step_time:.1f}ms per step)")
        
        elif pattern.pattern_type == "request_response_cycle":
            requests = metadata.get('requests_count', 0)
            responses = metadata.get('responses_count', 0)
            completion_ratio = metadata.get('completion_ratio', 0)
            
            return (f"üîÑ AGGREGATED: Request-response cycle "
                   f"({requests} requests, {responses} responses, "
                   f"{completion_ratio:.1%} completion, {duration:.1f}s)")
        
        elif pattern.pattern_type == "file_operations":
            operation_types = metadata.get('operation_types', {})
            files_affected = metadata.get('files_affected', [])
            total_ops = metadata.get('total_operations', pattern.count)
            
            ops_summary = ', '.join(f"{op}: {count}" for op, count in operation_types.items())
            files_summary = f"{len(files_affected)} files" if files_affected else "unknown files"
            
            return (f"üìÅ AGGREGATED: File operations batch "
                   f"[{ops_summary}] affecting {files_summary} ({duration:.1f}s)")
        
        elif pattern.pattern_type == "gui_updates":
            levels_dist = metadata.get('levels_distribution', {})
            files_involved = metadata.get('files_involved', [])
            
            return (f"üñ•Ô∏è AGGREGATED: GUI updates batch "
                   f"({pattern.count} updates across {len(files_involved)} files, {duration:.1f}s)")
        
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        priority = metadata.get('priority', 'unknown')
        table_suitable = metadata.get('table_suitable', False)
        table_indicator = "üìã" if table_suitable else "üìù"
        
        return (f"{table_indicator} AGGREGATED: {pattern.pattern_type} "
               f"({pattern.count} operations, {duration:.1f}s, priority: {priority})")
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
        stats = self.aggregation_stats.copy()
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã—Ö –º–µ—Ç—Ä–∏–∫
        if stats['patterns_processed'] > 0:
            stats['table_suitable_ratio'] = stats['table_suitable_patterns'] / stats['patterns_processed']
        else:
            stats['table_suitable_ratio'] = 0.0
        
        return stats

3. –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
3.1 –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (config.py)
from dataclasses import dataclass
from typing import Dict, Any, List

@dataclass
class ErrorExpansionConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫"""
    enabled: bool = True
    context_lines: int = 5
    trace_depth: int = 10
    immediate_expansion: bool = True  # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
    save_context: bool = True
    error_threshold_level: str = "WARNING"  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏

@dataclass
class TabularFormattingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    enabled: bool = True
    max_table_width: int = 120
    max_rows_per_table: int = 20
    ascii_tables: bool = True
    include_summaries: bool = True
    auto_format_patterns: List[str] = None  # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    
    def __post_init__(self):
        if self.auto_format_patterns is None:
            self.auto_format_patterns = [
                "plot_lines_addition",
                "cascade_component_initialization", 
                "request_response_cycle",
                "file_operations"
            ]

@dataclass
class AggregationConfig:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏
    buffer_size: int = 1000
    flush_interval: float = 2.0
    context_buffer_size: int = 20
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    min_pattern_entries: int = 3
    time_window_seconds: int = 5
    pattern_priority_threshold: str = "medium"
    
    # –ù–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫
    error_expansion: ErrorExpansionConfig = None
    
    # –ù–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    tabular_formatting: TabularFormattingConfig = None
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    max_processing_time_ms: float = 100.0
    enable_async_processing: bool = False
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–≤–æ–¥–∞
    compression_threshold: float = 0.3  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è
    output_format: str = "enhanced"  # "simple", "enhanced", "tabular"
    
    # –û—Ç–ª–∞–¥–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    enable_stats_logging: bool = True
    stats_interval_seconds: int = 60
    debug_mode: bool = False
    
    def __post_init__(self):
        if self.error_expansion is None:
            self.error_expansion = ErrorExpansionConfig()
        if self.tabular_formatting is None:
            self.tabular_formatting = TabularFormattingConfig()
    
    @classmethod
    def create_minimal(cls) -> 'AggregationConfig':
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return cls(
            buffer_size=500,
            flush_interval=1.0,
            min_pattern_entries=2,
            error_expansion=ErrorExpansionConfig(
                enabled=True,
                context_lines=3,
                immediate_expansion=True
            ),
            tabular_formatting=TabularFormattingConfig(
                enabled=True,
                max_table_width=80,
                max_rows_per_table=10
            )
        )
    
    @classmethod
    def create_performance(cls) -> 'AggregationConfig':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return cls(
            buffer_size=2000,
            flush_interval=0.5,
            min_pattern_entries=5,
            max_processing_time_ms=50.0,
            enable_async_processing=True,
            error_expansion=ErrorExpansionConfig(
                enabled=True,
                context_lines=2,
                immediate_expansion=False
            ),
            tabular_formatting=TabularFormattingConfig(
                enabled=False  # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            )
        )
    
    @classmethod
    def create_detailed(cls) -> 'AggregationConfig':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏"""
        return cls(
            buffer_size=1500,
            flush_interval=3.0,
            min_pattern_entries=2,
            context_buffer_size=50,
            error_expansion=ErrorExpansionConfig(
                enabled=True,
                context_lines=10,
                trace_depth=20,
                immediate_expansion=True,
                save_context=True
            ),
            tabular_formatting=TabularFormattingConfig(
                enabled=True,
                max_table_width=150,
                max_rows_per_table=30,
                include_summaries=True
            ),
            enable_stats_logging=True,
            debug_mode=True
        )
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        return {
            'buffer_size': self.buffer_size,
            'flush_interval': self.flush_interval,
            'context_buffer_size': self.context_buffer_size,
            'min_pattern_entries': self.min_pattern_entries,
            'time_window_seconds': self.time_window_seconds,
            'pattern_priority_threshold': self.pattern_priority_threshold,
            'error_expansion': {
                'enabled': self.error_expansion.enabled,
                'context_lines': self.error_expansion.context_lines,
                'trace_depth': self.error_expansion.trace_depth,
                'immediate_expansion': self.error_expansion.immediate_expansion,
                'save_context': self.error_expansion.save_context,
                'error_threshold_level': self.error_expansion.error_threshold_level
            },
            'tabular_formatting': {
                'enabled': self.tabular_formatting.enabled,
                'max_table_width': self.tabular_formatting.max_table_width,
                'max_rows_per_table': self.tabular_formatting.max_rows_per_table,
                'ascii_tables': self.tabular_formatting.ascii_tables,
                'include_summaries': self.tabular_formatting.include_summaries,
                'auto_format_patterns': self.tabular_formatting.auto_format_patterns
            },
            'max_processing_time_ms': self.max_processing_time_ms,
            'enable_async_processing': self.enable_async_processing,
            'compression_threshold': self.compression_threshold,
            'output_format': self.output_format,
            'enable_stats_logging': self.enable_stats_logging,
            'stats_interval_seconds': self.stats_interval_seconds,
            'debug_mode': self.debug_mode
        }

3.2 –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LoggerManager
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ logger_config.py

from log_aggregator.realtime_handler import AggregatingHandler
from log_aggregator.config import AggregationConfig, ErrorExpansionConfig, TabularFormattingConfig

class LoggerManager:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π LoggerManager —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    
    _aggregation_enabled = False
    _aggregation_config = None
    _aggregation_handlers = []
    
    @classmethod
    def configure_logging(
        cls,
        log_level: int = logging.DEBUG,
        console_level: Optional[int] = None,
        file_level: Optional[int] = None,
        log_file: Optional[str] = None,
        max_file_size: int = 10 * 1024 * 1024,
        backup_count: int = 5,
        enable_aggregation: bool = False,
        aggregation_config: Optional[dict] = None,
        enable_error_expansion: bool = True,  # –ù–û–í–´–ô –ø–∞—Ä–∞–º–µ—Ç—Ä
        enable_tabular_format: bool = True,   # –ù–û–í–´–ô –ø–∞—Ä–∞–º–µ—Ç—Ä
        aggregation_preset: str = "default", # –ù–û–í–´–ô –ø–∞—Ä–∞–º–µ—Ç—Ä: "minimal", "performance", "detailed"
    ) -> None:
        """
        –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
        
        –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
            enable_aggregation: –í–∫–ª—é—á–∏—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏—é –ª–æ–≥–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
            aggregation_config: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (buffer_size, flush_interval, etc.)
            enable_error_expansion: –í–∫–ª—é—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
            enable_tabular_format: –í–∫–ª—é—á–∏—Ç—å —Ç–∞–±–ª–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            aggregation_preset: –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ("minimal", "performance", "detailed")
        """
        # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        if enable_aggregation:
            cls._setup_enhanced_aggregation(
                root_logger, 
                aggregation_config or {}, 
                aggregation_preset,
                enable_error_expansion,
                enable_tabular_format
            )
        
        cls._configured = True
    
    @classmethod
    def _setup_enhanced_aggregation(cls, root_logger: logging.Logger, 
                                   config: dict, preset: str,
                                   enable_error_expansion: bool,
                                   enable_tabular_format: bool) -> None:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö handlers"""
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ—Å–µ—Ç–∞
        if preset == "minimal":
            cls._aggregation_config = AggregationConfig.create_minimal()
        elif preset == "performance":
            cls._aggregation_config = AggregationConfig.create_performance()
        elif preset == "detailed":
            cls._aggregation_config = AggregationConfig.create_detailed()
        else:
            cls._aggregation_config = AggregationConfig()
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        for key, value in config.items():
            if hasattr(cls._aggregation_config, key):
                setattr(cls._aggregation_config, key, value)
        
        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        cls._aggregation_config.error_expansion.enabled = enable_error_expansion
        cls._aggregation_config.tabular_formatting.enabled = enable_tabular_format
        
        # –ó–∞–º–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö handlers –Ω–∞ AggregatingHandler
        original_handlers = root_logger.handlers.copy()
        root_logger.handlers.clear()
        cls._aggregation_handlers = []
        
        for handler in original_handlers:
            aggregating_handler = AggregatingHandler(
                target_handler=handler,
                buffer_size=cls._aggregation_config.buffer_size,
                flush_interval=cls._aggregation_config.flush_interval,
                min_pattern_entries=cls._aggregation_config.min_pattern_entries,
                enabled=True,
                enable_error_expansion=cls._aggregation_config.error_expansion.enabled,
                enable_tabular_format=cls._aggregation_config.tabular_formatting.enabled,
                error_context_lines=cls._aggregation_config.error_expansion.context_lines
            )
            aggregating_handler.setLevel(handler.level)
            aggregating_handler.setFormatter(handler.formatter)
            root_logger.addHandler(aggregating_handler)
            cls._aggregation_handlers.append(aggregating_handler)
        
        cls._aggregation_enabled = True
        root_logger.info("Enhanced real-time log aggregation enabled with error expansion and tabular formatting")
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if cls._aggregation_config.debug_mode:
            root_logger.debug(f"Aggregation config: {cls._aggregation_config.to_dict()}")
    
    @classmethod
    def toggle_aggregation(cls, enabled: bool) -> None:
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –≤ runtime"""
        if not cls._aggregation_enabled:
            return
        
        for handler in cls._aggregation_handlers:
            handler.toggle_aggregation(enabled)
        
        root_logger = logging.getLogger(cls._root_logger_name)
        status = "enabled" if enabled else "disabled"
        root_logger.info(f"Real-time aggregation {status}")
    
    @classmethod
    def toggle_error_expansion(cls, enabled: bool) -> None:
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫ –≤ runtime"""
        if not cls._aggregation_enabled:
            return
        
        for handler in cls._aggregation_handlers:
            handler.toggle_error_expansion(enabled)
        
        root_logger = logging.getLogger(cls._root_logger_name)
        status = "enabled" if enabled else "disabled"
        root_logger.info(f"Error expansion {status}")
    
    @classmethod
    def toggle_tabular_format(cls, enabled: bool) -> None:
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤ runtime"""
        if not cls._aggregation_enabled:
            return
        
        for handler in cls._aggregation_handlers:
            handler.toggle_tabular_format(enabled)
        
        root_logger = logging.getLogger(cls._root_logger_name)
        status = "enabled" if enabled else "disabled"
        root_logger.info(f"Tabular formatting {status}")
    
    @classmethod
    def get_aggregation_stats(cls) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
        if not cls._aggregation_enabled:
            return {}
        
        combined_stats = {
            'handlers': {},
            'total_stats': {
                'total_records': 0,
                'aggregated_records': 0,
                'patterns_detected': 0,
                'errors_expanded': 0,
                'tables_generated': 0,
                'buffer_flushes': 0
            }
        }
        
        for i, handler in enumerate(cls._aggregation_handlers):
            handler_stats = handler.get_stats()
            combined_stats['handlers'][f'handler_{i}'] = handler_stats
            
            # –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            for key in combined_stats['total_stats']:
                if key in handler_stats:
                    combined_stats['total_stats'][key] += handler_stats[key]
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã—Ö –º–µ—Ç—Ä–∏–∫
        total_processed = combined_stats['total_stats']['total_records']
        if total_processed > 0:
            combined_stats['total_stats']['compression_ratio'] = (
                1 - combined_stats['total_stats']['aggregated_records'] / total_processed
            )
            combined_stats['total_stats']['error_expansion_ratio'] = (
                combined_stats['total_stats']['errors_expanded'] / total_processed
            )
        
        return combined_stats
    
    @classmethod
    def export_aggregation_config(cls) -> dict:
        """–≠–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
        if cls._aggregation_config:
            return cls._aggregation_config.to_dict()
        return {}
    
    @classmethod
    def update_aggregation_config(cls, config_updates: dict) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –≤ runtime"""
        if not cls._aggregation_enabled or not cls._aggregation_config:
            return
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        for key, value in config_updates.items():
            if hasattr(cls._aggregation_config, key):
                setattr(cls._aggregation_config, key, value)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫ handlers
        for handler in cls._aggregation_handlers:
            if 'buffer_size' in config_updates:
                handler.buffer_manager.max_size = config_updates['buffer_size']
            if 'flush_interval' in config_updates:
                handler.buffer_manager.flush_interval = config_updates['flush_interval']
            # –î–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –æ–±–Ω–æ–≤–ª—è–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        
        root_logger = logging.getLogger(cls._root_logger_name)
        root_logger.info("Aggregation configuration updated")

4. –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
4.1 –ü—Ä–∏–º–µ—Ä –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –æ—à–∏–±–∫–∏

–í—Ö–æ–¥–Ω—ã–µ –ª–æ–≥–∏:

2024-01-15 10:30:45 INFO Loading configuration file...
2024-01-15 10:30:45 INFO Initializing GUI components
2024-01-15 10:30:46 INFO Setting up plot window
2024-01-15 10:30:46 ERROR Failed to load data file: /path/to/data.csv


–í—ã–≤–æ–¥ —Å ErrorExpansionEngine:

================================================================================
üö® DETAILED ERROR ANALYSIS - ERROR
================================================================================
üìç Location: data_loader.py:45
‚è∞ Time: 2024-01-15 10:30:46
üí¨ Message: Failed to load data file: /path/to/data.csv

üìã PRECEDING CONTEXT:
----------------------------------------
  1. [INFO] Setting up plot window (0.2s ago)
  2. [INFO] Initializing GUI components (1.0s ago)
  3. [INFO] Loading configuration file... (1.1s ago)

üîó RELATED OPERATIONS:
----------------------------------------
  1. [INFO] data_loader.py:23 - Opening file dialog
  2. [INFO] data_loader.py:35 - User selected file: /path/to/data.csv

üí° SUGGESTED ACTIONS:
----------------------------------------
  1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
  2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—É—Ç–∏
  3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
  4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–¥ –≤ —Ñ–∞–π–ª–µ data_loader.py:45

================================================================================

4.2 –ü—Ä–∏–º–µ—Ä —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏–Ω–∏–π

–í—Ö–æ–¥–Ω—ã–µ –ª–æ–≥–∏:

2024-01-15 10:31:00 INFO Adding a new line 'Temperature_1' to the plot
2024-01-15 10:31:00 INFO Adding a new line 'Temperature_2' to the plot
2024-01-15 10:31:00 INFO Adding a new line 'Pressure_1' to the plot
2024-01-15 10:31:01 INFO Adding a new line 'Pressure_2' to the plot
2024-01-15 10:31:01 INFO Adding a new line 'Humidity' to the plot


–í—ã–≤–æ–¥ —Å TabularFormatter:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìä Plot Lines Addition Summary                                                                                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ #  ‚îÇ Line Name      ‚îÇ Time        ‚îÇ Duration (ms) ‚îÇ Status     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1  ‚îÇ Temperature_1  ‚îÇ +0.0ms      ‚îÇ 0.0           ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 2  ‚îÇ Temperature_2  ‚îÇ +150.2ms    ‚îÇ 150.2         ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 3  ‚îÇ Pressure_1     ‚îÇ +320.5ms    ‚îÇ 320.5         ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 4  ‚îÇ Pressure_2     ‚îÇ +890.1ms    ‚îÇ 890.1         ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 5  ‚îÇ Humidity       ‚îÇ +1200.3ms   ‚îÇ 1200.3        ‚îÇ ‚úÖ Success ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
üìä Total: 5 lines added in 1200.3ms (avg: 240.1ms per line)

4.3 –ü—Ä–∏–º–µ—Ä —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–∞—Å–∫–∞–¥–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

–í—Ö–æ–¥–Ω—ã–µ –ª–æ–≥–∏:

2024-01-15 10:32:00 INFO Initializing ConfigManager
2024-01-15 10:32:00 INFO Initializing DatabaseConnection
2024-01-15 10:32:01 INFO Initializing PlotEngine
2024-01-15 10:32:01 INFO Initializing GUIManager
2024-01-15 10:32:02 INFO Initializing EventHandler


–í—ã–≤–æ–¥ —Å TabularFormatter:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üîß Component Initialization Cascade                                                                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Step ‚îÇ Component           ‚îÇ Time        ‚îÇ Duration (ms) ‚îÇ Status ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1    ‚îÇ ConfigManager       ‚îÇ +0.0ms      ‚îÇ 0.0           ‚îÇ ‚úÖ OK  ‚îÇ
‚îÇ 2    ‚îÇ DatabaseConnection  ‚îÇ +120.5ms    ‚îÇ 120.5         ‚îÇ ‚úÖ OK  ‚îÇ
‚îÇ 3    ‚îÇ PlotEngine          ‚îÇ +650.2ms    ‚îÇ 529.7         ‚îÇ ‚úÖ OK  ‚îÇ
‚îÇ 4    ‚îÇ GUIManager          ‚îÇ +1100.8ms   ‚îÇ 450.6         ‚îÇ ‚úÖ OK  ‚îÇ
‚îÇ 5    ‚îÇ EventHandler        ‚îÇ +1800.3ms   ‚îÇ 699.5         ‚îÇ ‚úÖ OK  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
üìä Initialization cascade: 5 components in 1800.3ms

4.4 –ü—Ä–∏–º–µ—Ä —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

–í—Ö–æ–¥–Ω—ã–µ –ª–æ–≥–∏:

2024-01-15 10:33:00 INFO Loading experiment_1.json
2024-01-15 10:33:01 INFO Saving results to output.csv
2024-01-15 10:33:01 INFO Loading calibration.dat
2024-01-15 10:33:02 INFO Saving backup to backup_001.json


–í—ã–≤–æ–¥ —Å TabularFormatter:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìÅ File Operations Summary                                                                                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ #  ‚îÇ Operation ‚îÇ File                ‚îÇ Time         ‚îÇ Status     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1  ‚îÇ Load      ‚îÇ experiment_1.json   ‚îÇ 10:33:00.000 ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 2  ‚îÇ Save      ‚îÇ output.csv          ‚îÇ 10:33:01.200 ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 3  ‚îÇ Load      ‚îÇ calibration.dat     ‚îÇ 10:33:01.850 ‚îÇ ‚úÖ Success ‚îÇ
‚îÇ 4  ‚îÇ Save      ‚îÇ backup_001.json     ‚îÇ 10:33:02.100 ‚îÇ ‚úÖ Success ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
üìä File operations: load: 2, save: 2

5. Workflow –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –Ω–æ–≤—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
5.1 –û–±—â–∏–π workflow
–í—Ö–æ–¥—è—â–∏–π LogRecord
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ AggregatingHandler ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ä–æ–≤–Ω—è
        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ ERROR/‚îÇ ‚îÄ‚îÄYES‚îÄ‚îÄ‚ñ∫ ErrorExpansionEngine ‚îÄ‚îÄ‚ñ∫ –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥
    ‚îÇWARNING‚îÇ                                   —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ NO
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  BufferManager  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       –¥–ª—è –±—É–¥—É—â–∏—Ö –æ—à–∏–±–æ–∫
        ‚îÇ
        ‚ñº
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π
    –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PatternDetector ‚îÇ ‚îÄ‚îÄ‚ñ∫ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇAggregationEngine‚îÇ ‚îÄ‚îÄ‚ñ∫ –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     –∑–∞–ø–∏—Å–µ–π
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇTabularFormatter ‚îÇ ‚îÄ‚îÄ‚ñ∫ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        ‚îÇ
        ‚ñº
    –í—ã–≤–æ–¥ –≤ target_handler

5.2 Workflow –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
ERROR/WARNING LogRecord
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ErrorExpansionEngine ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚îÇ ‚óÑ‚îÄ‚îÄ BufferManager.get_recent_context()
‚îÇ –∏–∑ BufferManager    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é- ‚îÇ
‚îÇ —â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö     ‚îÇ
‚îÇ –æ–ø–µ—Ä–∞—Ü–∏–π            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è       ‚îÇ
‚îÇ —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è           ‚îÇ
‚îÇ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω-  ‚îÇ
‚îÇ –Ω–æ–≥–æ LogRecord      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
    –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥

5.3 Workflow —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TabularFormatter    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
    –ü—Ä–æ–≤–µ—Ä–∫–∞ table_suitable
    –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ TRUE  ‚îÇ ‚îÄ‚îÄ‚ñ∫ –°–æ–∑–¥–∞–Ω–∏–µ TableData
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ FALSE
        ‚ñº
    –ü—Ä–æ–ø—É—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞    ‚îÇ
‚îÇ —Ç–∞–±–ª–∏—Ü—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö   ‚îÇ
‚îÇ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –†–∞—Å—á–µ—Ç —à–∏—Ä–∏–Ω—ã       ‚îÇ
‚îÇ –∫–æ–ª–æ–Ω–æ–∫             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ      ‚îÇ
‚îÇ ASCII —Ç–∞–±–ª–∏—Ü—ã       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –°–æ–∑–¥–∞–Ω–∏–µ TableRecord‚îÇ
‚îÇ LogRecord           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫ –≤—ã–≤–æ–¥—É

6. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
6.1 –¢–µ—Å—Ç—ã –¥–ª—è ErrorExpansionEngine
# tests/test_error_expansion.py

import unittest
from datetime import datetime, timedelta
from log_aggregator.error_expansion import ErrorExpansionEngine, ErrorContext
from log_aggregator.realtime_handler import LogRecord

class TestErrorExpansionEngine(unittest.TestCase):
    
    def setUp(self):
        self.engine = ErrorExpansionEngine(context_lines=3, trace_depth=5)
        self.base_time = datetime.now()
    
    def test_error_expansion_with_context(self):
        """–¢–µ—Å—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –æ—à–∏–±–∫–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        context_records = [
            LogRecord(
                timestamp=self.base_time - timedelta(seconds=2),
                level="INFO",
                filename="test.py",
                line_number=10,
                message="Loading configuration",
                raw_record=None
            ),
            LogRecord(
                timestamp=self.base_time - timedelta(seconds=1),
                level="INFO", 
                filename="test.py",
                line_number=15,
                message="Initializing components",
                raw_record=None
            )
        ]
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –æ—à–∏–±–∫–∏
        error_record = LogRecord(
            timestamp=self.base_time,
            level="ERROR",
            filename="test.py", 
            line_number=20,
            message="Failed to load file not found",
            raw_record=None
        )
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –æ—à–∏–±–∫–∏
        expanded_record = self.engine.expand_error(error_record, context_records)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏
        self.assertIn("DETAILED ERROR ANALYSIS", expanded_record.getMessage())
        self.assertIn("PRECEDING CONTEXT", expanded_record.getMessage())
        self.assertIn("Loading configuration", expanded_record.getMessage())
        self.assertIn("SUGGESTED ACTIONS", expanded_record.getMessage())
        self.assertEqual(self.engine.stats['errors_processed'], 1)
    
    def test_error_classification(self):
        """–¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫"""
        test_cases = [
            ("file not found error", "file_not_found"),
            ("memory allocation failed", "memory_error"),
            ("widget rendering error", "gui_error"),
            ("division by zero", "calculation_error"),
            ("unknown error type", "unknown")
        ]
        
        for message, expected_type in test_cases:
            error_record = LogRecord(
                timestamp=self.base_time,
                level="ERROR",
                filename="test.py",
                line_number=1,
                message=message,
                raw_record=None
            )
            
            error_type = self.engine._classify_error(error_record)
            self.assertEqual(error_type, expected_type)
    
    def test_suggestions_generation(self):
        """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        error_record = LogRecord(
            timestamp=self.base_time,
            level="ERROR",
            filename="data_loader.py",
            line_number=45,
            message="file not found",
            raw_record=None
        )
        
        suggestions = self.engine._generate_suggestions("file_not_found", error_record)
        
        self.assertIn("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞", suggestions)
        self.assertIn("data_loader.py:45", suggestions[-1])

6.2 –¢–µ—Å—Ç—ã –¥–ª—è TabularFormatter
# tests/test_tabular_formatter.py

import unittest
from datetime import datetime, timedelta
from log_aggregator.tabular_formatter import TabularFormatter, TableData
from log_aggregator.pattern_detector import PatternGroup
from log_aggregator.realtime_handler import LogRecord

class TestTabularFormatter(unittest.TestCase):
    
    def setUp(self):
        self.formatter = TabularFormatter(max_table_width=80, max_rows_per_table=10)
        self.base_time = datetime.now()
    
    def test_plot_lines_table_creation(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏–Ω–∏–π"""
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        records = []
        for i, line_name in enumerate(['Temperature_1', 'Temperature_2', 'Pressure_1']):
            record = LogRecord(
                timestamp=self.base_time + timedelta(milliseconds=i*100),
                level="INFO",
                filename="plot.py",
                line_number=25,
                message=f"Adding a new line '{line_name}' to the plot",
                raw_record=None
            )
            records.append(record)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        pattern = PatternGroup(
            pattern_type="plot_lines_addition",
            records=records,
            start_time=records[0].timestamp,
            end_time=records[-1].timestamp,
            metadata={'table_suitable': True}
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        table_data = self.formatter._create_plot_lines_table(pattern)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏
        self.assertEqual(table_data.title, "üìä Plot Lines Addition Summary")
        self.assertEqual(len(table_data.rows), 3)
        self.assertIn("Temperature_1", table_data.rows[0][1])
        self.assertIn("Temperature_2", table_data.rows[1][1])
        self.assertIn("Pressure_1", table_data.rows[2][1])
        self.assertIn("Total: 3 lines added", table_data.summary)
    
    def test_ascii_table_formatting(self):
        """–¢–µ—Å—Ç ASCII —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã"""
        table_data = TableData(
            title="Test Table",
            headers=["Col1", "Col2", "Col3"],
            rows=[
                ["Row1", "Data1", "Value1"],
                ["Row2", "Data2", "Value2"]
            ],
            summary="Test summary"
        )
        
        ascii_table = self.formatter._format_ascii_table(table_data)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏
        self.assertIn("Test Table", ascii_table)
        self.assertIn("Col1", ascii_table)
        self.assertIn("Row1", ascii_table)
        self.assertIn("Test summary", ascii_table)
        self.assertIn("‚îå", ascii_table)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—Ü —Ç–∞–±–ª–∏—Ü—ã
        self.assertIn("‚îî", ascii_table)
    
    def test_column_width_calculation(self):
        """–¢–µ—Å—Ç —Ä–∞—Å—á–µ—Ç–∞ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫"""
        table_data = TableData(
            title="Test",
            headers=["Short", "Very Long Header Name", "Med"],
            rows=[
                ["A", "Short", "Medium Length"],
                ["Very Long Data", "B", "C"]
            ]
        )
        
        col_widths = self.formatter._calculate_column_widths(table_data)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏
        self.assertEqual(len(col_widths), 3)
        self.assertGreaterEqual(col_widths[0], len("Very Long Data"))
        self.assertGreaterEqual(col_widths[1], len("Very Long Header Name"))
        self.assertGreaterEqual(col_widths[2], len("Medium Length"))

6.3 –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
# tests/test_integration.py

import unittest
import logging
from datetime import datetime, timedelta
from log_aggregator.realtime_handler import AggregatingHandler
from log_aggregator.config import AggregationConfig

class TestIntegration(unittest.TestCase):
    
    def setUp(self):
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ handler
        self.target_handler = logging.StreamHandler()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = AggregationConfig.create_detailed()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ AggregatingHandler
        self.aggregating_handler = AggregatingHandler(
            target_handler=self.target_handler,
            buffer_size=config.buffer_size,
            flush_interval=config.flush_interval,
            min_pattern_entries=config.min_pattern_entries,
            enabled=True,
            enable_error_expansion=config.error_expansion.enabled,
            enable_tabular_format=config.tabular_formatting.enabled,
            error_context_lines=config.error_expansion.context_lines
        )
    
    def test_error_immediate_processing(self):
        """–¢–µ—Å—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        info_record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Loading data",
            args=(),
            exc_info=None
        )
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.aggregating_handler.emit(info_record)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –æ—à–∏–±–∫–∏
        error_record = logging.LogRecord(
            name="test",
            level=logging.ERROR,
            pathname="test.py", 
            lineno=15,
            msg="File not found",
            args=(),
            exc_info=None
        )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π)
        initial_errors = self.aggregating_handler.stats['errors_expanded']
        self.aggregating_handler.emit(error_record)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –æ—à–∏–±–∫–∞ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
        self.assertEqual(
            self.aggregating_handler.stats['errors_expanded'], 
            initial_errors + 1
        )
    
    def test_pattern_detection_and_table_generation(self):
        """–¢–µ—Å—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü"""
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–∏–∏ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        base_time = datetime.now().timestamp()
        
        for i in range(5):
            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="plot.py",
                lineno=20,
                msg=f"Adding a new line 'Line_{i}' to the plot",
                args=(),
                exc_info=None
            )
            record.created = base_time + i * 0.1
            self.aggregating_handler.emit(record)
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞
        self.aggregating_handler._process_buffer()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = self.aggregating_handler.get_stats()
        self.assertGreater(stats['patterns_detected'], 0)
        self.assertGreater(stats['tables_generated'], 0)
    
    def test_configuration_updates(self):
        """–¢–µ—Å—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ runtime"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.assertTrue(self.aggregating_handler.enable_error_expansion)
        self.assertTrue(self.aggregating_handler.enable_tabular_format)
        
        # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.aggregating_handler.toggle_error_expansion(False)
        self.aggregating_handler.toggle_tabular_format(False)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        self.assertFalse(self.aggregating_handler.enable_error_expansion)
        self.assertFalse(self.aggregating_handler.enable_tabular_format)
        
        # –í–∫–ª—é—á–µ–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ
        self.aggregating_handler.toggle_error_expansion(True)
        self.aggregating_handler.toggle_tabular_format(True)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        self.assertTrue(self.aggregating_handler.enable_error_expansion)
        self.assertTrue(self.aggregating_handler.enable_tabular_format)

7. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ª–æ–≥–æ–≤ —Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç –¥–≤–∞ –≤–∞–∂–Ω—ã—Ö –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞:

7.1 ErrorExpansionEngine
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∑–∞–ø–∏—Å–µ–π —É—Ä–æ–≤–Ω—è WARNING/ERROR
–ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ –±–µ–∑ –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏
–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–æ–∫ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
7.2 TabularFormatter
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—ã
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–∞–±–ª–∏—Ü –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
ASCII —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
–°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã
7.3 –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –æ—à–∏–±–æ–∫: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è –ø–æ–ª—É—á–∞—é—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤ —É–¥–æ–±–Ω–æ–º —Ç–∞–±–ª–∏—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
–ì–∏–±–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–µ –≤–ª–∏—è—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å: –õ–µ–≥–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–∏–ø–æ–≤ —Ç–∞–±–ª–∏—Ü –∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –æ—à–∏–±–æ–∫

–ú–æ–¥—É–ª—å –æ—Å—Ç–∞–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞—Ç–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º –∏ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ —Å –Ω–æ–≤—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏, —Ç–∞–∫ –∏ –±–µ–∑ –Ω–∏—Ö, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.