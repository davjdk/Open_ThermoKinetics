# Техническое задание: Рефакторинг системы агрегации логов (проект solid-state-kinetics)

## 1. Основные сущности и понятия

- **Операция** – логически завершённый каскад вычислений, инициированный единичным действием пользователя. Операция характеризуется ограниченными рамками времени и **всегда начинается и заканчивается внутри одного метода** (например, `_handle_add_new_series`). В ходе выполнения операции могут генерироваться множественные лог-сообщения, но все они относятся к одной логической задаче пользователя.

- **Поток вычислений (Flow)** – последовательность операций и служебных действий, происходящих при моделировании или обработке данных. Поток может включать несколько операций, выполняемых последовательно или параллельно, и **не ограничен по времени одним методом**. Например, долговременный процесс оптимизации или моделирования можно рассматривать как поток, содержащий множество операций. Новая система логирования должна учитывать существование потоков, однако в данном рефакторинге основной упор делается на явное логирование отдельных операций.

## 2. Новая архитектура логгера операций

Новая архитектура должна расширить текущую систему агрегации логов, позволяя **явно обозначать границы операций** в коде, сохраняя при этом использование существующей инфраструктуры. Для этого планируются следующие изменения:

- **Ручное обозначение начала и конца операций.** Разработчики смогут в коде вызывать специальные методы (например, `start_operation("OP_NAME")` и `end_operation()`) или использовать контекстный менеджер/декоратор для явного логирования начала и окончания каждой операции. Это гарантирует, что каждая пользовательская операция ясно выделена в логах, вместо опоры исключительно на автоматические эвристики.

- **Использование существующих компонентов.** Новая функциональность будет встроена поверх текущих классов логгирования: `AggregatingHandler`, `OperationAggregator`, `OperationMonitor`, `AggregationEngine`, `BufferedLogRecord` и др. Полностью переписывать систему не потребуется – вместо этого мы дополним её возможностью явной маркировки операций. Это обеспечивает совместимость с существующим кодом и минимальные изменения в конфигурации логирования.

- **Представление операции как таблицы.** После рефакторинга **каждая завершённая операция будет выводиться в лог в виде отдельной таблицы** (форматируется через `TabularFormatter`). Строки таблицы будут представлять подэтапы или отдельные действия внутри операции, а столбцы – ключевые параметры каждого подэтапа. Подэтапами считаются важные шаги, произошедшие в ходе операции (например, вызовы внутренних компонентов, запросы/ответы, завершение этапов алгоритма и т.д.). Столбцы таблицы операций включат, в том числе:
  - Время начала подэтапа и время окончания подэтапа.
  - Продолжительность подэтапа (в мс или с).
  - Число запросов/ответов (request-response) в рамках подэтапа или операции.
  - Флаг наличия ошибок или предупреждений в ходе подэтапа.
  - Названия задействованных компонентов или модулей.
  - Любые дополнительные метрики, вычисляемые плагинами (например, использование CPU, идентификатор пользователя и т.д.).

Каждая такая таблица позволит в структурированном виде отразить ход выполнения одной операции пользователя. В конце таблицы может добавляться **итоговая строка-сводка** с агрегированными показателями по всей операции (например, общее время, общее число вызовов, статус успех/неуспех). Применение `TabularFormatter` для вывода таблиц обеспечивает удобочитаемый ASCII-формат, аналогичный уже используемому для других агрегированных паттернов.

## 3. Эвристики группировки логов в операции

В дополнение к явной маркировке, система будет поддерживать несколько эвристик для группирования входящих лог-сообщений в границы операции:

- **Явное логирование через API.** Основной способ – явный вызов методов начала и завершения операции в коде. Разработчик вручную вызывает `start_operation("OP_NAME")` в начале метод-обработчика действия пользователя и `end_operation()` непосредственно перед выходом из метода. Эта пара вызовов гарантирует, что все лог-сообщения между ними будут отнесены к одной операции с именем **OP_NAME**. Внутренне такой вызов может записывать специальные сообщения в лог (например, `INFO: OPERATION START: OP_NAME` и `INFO: OPERATION END: OP_NAME`), которые перехватываются логгером и инициируют начало/завершение агрегирования операции. В явном режиме эвристика временного окна не используется – границы операции определяются четко вызовами API.

- **Контекстный менеджер / декоратор.** Для удобства разработки будет предоставлен контекстный менеджер (например, `with log_operation("OP_NAME"):`) либо декоратор `@log_operation("OP_NAME")`. Эти механизмы автоматически оборачивают выполнение блока кода или функции логированием начала и конца операции. При входе в контекст или начале выполнения декорированной функции логгер зафиксирует начало операции **OP_NAME**, при выходе – автоматически зафиксирует окончание. Такой подход снижает риск забыть вызвать `end_operation()` и делает код чище. Он может быть реализован с помощью тех же методов `start_operation()`/`end_operation()` внутри менеджера/декоратора.

- **Автоматическое закрытие по таймауту (неполный request-response цикл).** Для случаев, когда по какой-либо причине операция не была явно закрыта (например, отсутствие соответствующего ответа на запрос), вводится эвристика на уровне мониторинга запросов: **если обнаружен запрос без пары ответ в течение заданного таймаута**, логгер автоматически пометит завершение операции. Данный механизм базируется на существующей логике `OperationMonitor`, отслеживающей запросы и ответы. Если, к примеру, метод `handle_request_cycle` инициировал запрос, но ответ не поступил (возможно, из-за исключения или отмены операции), то по истечении N секунд `OperationMonitor` или сам `OperationAggregator` завершит текущую операцию принудительно, пометив её статусом *«прервано по таймауту»* либо *«неуспешно»*. Это предотвратит зависание незакрытых групп операций в агрегаторе. Таймаут будет настраиваемым параметром (например, 5 секунд по умолчанию). 

Каждая из этих эвристик дополняет друг друга. **Приоритет отдается явной маркировке**: если разработчик явно обозначил границы операции, они используются безусловно. Контекстный менеджер и декоратор – это лишь синтаксический сахар над тем же механизмом. Автоматическое закрытие по таймауту служит страховкой от некорректного поведения или исключительных ситуаций, обеспечивая завершение операции даже при отсутствии явного сигнала окончания.

## 4. Изменения и новые компоненты системы

Для реализации описанной архитектуры потребуются следующие доработки существующих компонентов и добавление новых:

### 4.1. `OperationAggregator` – поддержка явного режима операций

Необходимо переработать `OperationAggregator` для поддержки нового **ручного режима** агрегации операций. В текущей реализации `OperationAggregator` автоматически обнаруживает «каскады» операций на основе шаблонов сообщений и временных окон. После рефакторинга его работа разделится на два режима:

- **Автоматический режим (как сейчас):** при включенной автоматической агрегации `OperationAggregator` продолжит собирать каскады операций на основе эвристик и паттернов (например, по сообщениям вида *“handle_request_from_main_tab ...”*, *“operation 'X' completed”* и т.п.). Этот режим обеспечивает обратную совместимость и поддержку существующих паттернов, например, для операций, которые не были помечены вручную.

- **Явный режим:** если разработчик вызывает `start_operation()`, агрегатор должен начать новую группу операций (создать новый `OperationGroup`) вне зависимости от содержания сообщения. **Логика определения начала каскада в явном режиме полностью управляется вызовами API, а не шаблонами сообщений или временем.** В момент `start_operation("NAME")` текущая открытая группа (если она есть) должна быть немедленно закрыта и зафиксирована, после чего открывается новая группа с именем операции NAME. При вызове `end_operation()` текущая группа помечается как завершённая и передается на формирование итогового результата (таблицы). Таким образом, OperationAggregator будет расширен методами:
  - `start_operation(name: str)`: закрывает предыдущую операцию (если открыта) и начинает новую с указанным именем.
  - `end_operation()`: завершает текущую операцию и инициирует генерацию агрегированного лог-записи (таблицы) по ней.

В рамках этих изменений потребуется скорректировать существующий метод `process_record`: при явном режиме, вероятно, не нужно полагаться на `cascade_window` для закрытия групп – вместо этого `end_operation()` вызывает внутренний метод аналогичный текущему `_close_current_group()`, не ожидая истечения времени. Также, нужно учесть, что **сообщения типа** `"OPERATION START: X"` и `"OPERATION END: X"` больше не будут просто шаблонами для поиска, а станут сигналами к вызову соответствующих методов. (При желании поддержать старый стиль через лог-сообщения, можно оставить шаблоны в `operation_patterns`, но при их обнаружении лучше сразу переключаться на ручное управление.) 

Важно: в статистике OperationAggregator следует добавить учет явных операций (например, считать общее число операций, закрытых вручную vs автоматически). При включенном явном режиме, вероятно, стоит отключить попытки автоматического определения границ по паттернам, чтобы избежать конфликтов.

### 4.2. `OperationMonitor` – расширение под произвольные метрики

`OperationMonitor` отвечает за отслеживание жизненного цикла операций, особенно запросов и ответов (request-response циклов). В рамках рефакторинга его функциональность будет расширена, чтобы собирать и хранить **дополнительные метрики для каждой операции**. Планируемые доработки:

- **Хранение произвольных столбцов (custom metrics).** В OperationMonitor будет добавлена структура (например, словарь `custom_metrics` или расширенная модель данных операции), куда можно записывать любые дополнительные параметры, относящиеся к текущей операции. Это может включать: имя пользователя, запустившего операцию; среднюю загрузку CPU за время операции; объём обработанных данных; статус завершения (успех, неуспех); и др. Идея в том, что OperationMonitor станет центральным накопителем информации об операции, а не только фиксировать время начала/окончания и соответствие запрос-ответ. 

- **Подсчет запросов/ответов.** Так как OperationMonitor уже коррелирует запросы и ответы, он может предоставить количественную метрику: **число запросов в рамках данной операции**. Каждый раз при связывании пары запрос-ответ или обнаружении одиночного запроса без ответа, счётчик увеличивается. Эта величина будет сохранена и затем отображена в таблице операции отдельным столбцом (см. п.7а).

- **Интеграция с OperationAggregator.** При явном старте операции OperationMonitor должен быть уведомлен о начале нового отслеживаемого цикла (например, для сброса счетчиков или инициализации сбора метрик). Это может быть реализовано вызовом OperationMonitor из `start_operation()`. Аналогично, при завершении операции OperationMonitor может прикрепить к итоговым данным операции все накопленные метрики (число запросов, накопленные предупреждения/ошибки и пр.). 

- **Отслеживание потоков.** Хотя основная цель – операции, OperationMonitor также будет продолжать (или начать) отслеживать более длительные процессы (потоки). Например, если есть длительный процесс моделирования без чётких границ, OperationMonitor может агрегировать метрики на протяжении всего процесса. Однако в текущем рефакторинге фокус на операциях, поэтому поддержку потоков можно оставить как есть (или в виде задела на будущее), чтобы не усложнять реализацию.

После доработки OperationMonitor станет более универсальным: помимо корреляции запросов и измерения латентности операций, он будет накапливать произвольные показатели. Интерфейс OperationMonitor может быть дополнен методами вида `add_metric(key, value)` для записи метрик в текущий контекст операции, чтобы плагины или другие части системы могли легко добавить нужную информацию.

### 4.3. `OperationTableBuilder` – сбор данных операции в табличный вид

Будет добавлен новый компонент **`OperationTableBuilder`**, отвечающий за преобразование собранных данных операции в формат, пригодный для вывода `TabularFormatter`. Его основные функции:

- **Агрегация логов операции.** Получив завершённую группу операции (например, объект `OperationGroup` из OperationAggregator или аналогичную структуру), `OperationTableBuilder` извлекает из неё все необходимые данные для таблицы. Это включает список подэтапов (например, имена операций или действий внутри каскада), их временные метки начала/окончания, длительности, а также метрики, предоставленные OperationMonitor и другими источниками. Если в `OperationGroup` хранится сырая информация (список `records` логов, набор `actors` и т.п.), то `OperationTableBuilder` трансформирует это в строки таблицы:
  - Каждая строка представляет подэтап. Например, если операция *“ADD_REACTION”* инициировала подкапотные действия *“GET_DF_DATA”*, *“SMOOTH_DATA”* и *“PLOT_UPDATE”*, то для каждого из них будет строка с показателями.
  - Если операция более плоская (не разбивается на именованные подшаги), можно трактовать каждое значимое лог-сообщение как отдельное действие (или, например, каждый связанный request-response как действие).

- **Определение столбцов таблицы.** `OperationTableBuilder` формирует набор столбцов, соответствующий требованиям (время начала, время окончания, длительность, кол-во запросов, ошибки/предупреждения, компонент, и т.д.). Базовый набор столбцов фиксированный (см. раздел 7), но компонент должен быть **адаптивным** – уметь добавлять дополнительные столбцы, если в `custom_metrics` операции присутствуют новые ключи. Например, если для данной операции записана метрика `user_name` или `cpu_load`, `OperationTableBuilder` добавит колонку "User" или "CPU Load" и заполнит соответствующие ячейки. Это позволяет легко расширять набор метрик в будущем без изменения форматирования.

- **Поддержка плагинов метрик.** `OperationTableBuilder` будет взаимодействовать с потенциальными плагинами: небольшими функциями или классами, которые могут принимать информацию об операции (например, список log records) и вычислять дополнительную метрику. Сами плагины регистрируются заранее. При сборке таблицы `OperationTableBuilder` может вызывать эти плагины и включать их результаты в `custom_metrics`. Пример: плагин, вычисляющий среднюю загрузку CPU за интервал операции, или плагин, определяющий размер обработанных данных. 

- **Выходной формат данных.** Результатом работы `OperationTableBuilder` является объект табличных данных – например, экземпляр `TableData` (как определено в `TabularFormatter`) или `BufferedLogRecord` содержащий уже отформатированную таблицу. Скорее всего, целесообразно генерировать структурированный объект `TableData` с заголовком, списком заголовков столбцов, строками и необязательной итоговой строкой-сводкой. Поля `TableData` могут быть заполнены следующим образом:
  - `title`: название операции (например, **"🟢 Операция ADD_REACTION"** или просто имя в удобочитаемом виде).
  - `headers`: список названий столбцов (Время начала, Время окончания, Длительность, …).
  - `rows`: список строк, каждая из которых – список ячеек (строки формируются по каждому подэтапу).
  - `summary`: строка с итоговой сводкой по операции (например, *"Итог: 3 подэтапа, общее время 2.5 c, 1 предупреждение"*).
  - Возможно `table_type`: указатель типа (например, `"operation_summary"`), чтобы `TabularFormatter` мог при необходимости применить особое форматирование.

Этот новый компонент будет вызываться OperationAggregator сразу после завершения операции (либо внутри `end_operation()` метода). Он изолирует логику построения таблицы, что улучшает **разделение обязанностей**: OperationAggregator собирает/закрывает группы, OperationMonitor собирает показатели, а OperationTableBuilder строит финальную таблицу для вывода.

## 5. Интеграция с `TabularFormatter`

Форматирование таблиц операций будет происходить с помощью существующего механизма `TabularFormatter`, обеспечивающего генерацию структурированных ASCII-таблиц. Интеграция предусматривает:

- **Новый тип таблицы для операций.** В `TabularFormatter` может быть добавлен специальный форматтер для типа паттерна "operation" (либо "operation_summary"). Аналогично тому, как сейчас имеются форматтеры для `plot_lines_addition`, `file_operations`, `request_response_cycle` и др., появится обработчик, способный принять `TableData` операции и сформировать ASCII-таблицу. Если добавлять новый тип неудобно, можно использовать существующий метод генерации общего случая (generic), так как `OperationTableBuilder` уже выдаст полностью подготовленные строки и заголовки.

- **Вывод операций как отдельных записей.** Каждая завершённая операция будет отправляться в лог через `AggregatingHandler` как отдельная запись (вероятно уровня INFO). Этот запись будет содержать уже форматированный текст таблицы. В агрегированном логе (например, `aggregated.log`) такие записи будут легко узнаваемы по рамке таблицы и названию операции в заголовке.

- **Поддержка дополнительных полей через `metadata`.** Если потребуется передать в `TabularFormatter` какие-то дополнительные данные, не вписывающиеся напрямую в строки таблицы (например, информация о пользователе или контексте), можно использовать поле `metadata` в `BufferedLogRecord` или расширить `TableData`. Планируется задействовать уже существующую возможность добавлять поля в лог-записи (например, extra-атрибуты LogRecord) и модифицировать `TabularFormatter` так, чтобы он мог отображать такие поля либо включать их в текст заголовка/итоговой строки. **Дополнительные метрики**, сохранённые в `OperationMonitor.custom_metrics`, должны быть отображены: либо как отдельные колонки (если значений несколько и они числовые или категориальные), либо как часть статусной информации. 

- **Итоговая строка-сводка.** `TabularFormatter` будет формировать нижнюю строку после таблицы, кратко резюмируя операцию: количество подэтапов (строк), общее время выполнения операции, количество запросов, наличие ошибок/предупреждений. Эта строка будет формироваться на основе полей, которые передаст `OperationTableBuilder` (например, длина списка подэтапов, суммарное время, флаги ошибок). Использование `summary` поля `TableData` упростит добавление этой информации.

Отметим, что `TabularFormatter` изначально разрабатывался для подобной задачи – структурированного вывода агрегированных данных – поэтому мы максимально используем его потенциал, а не создаём собственный форматировщик. Все новые таблицы операций будут соответствовать общему стилю (рамки, ASCII-таблица с заголовками), обеспечивая единообразие с существующими сводками (например, таблицами запрос-ответ или файловых операций в текущем логе).

## 6. Примеры интеграции и изменения в коде использования

После внедрения новой системы, **существующий код приложения и лог-файлы послужат примером интеграции**. В частности, необходимо будет обновить участки кода, где происходят пользовательские действия, чтобы они явно логировали операции:

- **Изменение обработчиков в `main_window.py`.** Методы, которые инициируют важные операции, должны использовать новый механизм. Например, метод `_handle_add_new_series` (добавление новой серии данных) в начале вызовет `logger.start_operation("ADD_NEW_SERIES")`, а перед выходом – `logger.end_operation()`. Таким образом, все логи, связанные с добавлением серии (загрузка файла, обновление графика, расчёт кинетики и пр.), будут заключены между этими вызовами и агрегированы в одну таблицу операции. В случае использования декоратора `@log_operation("ADD_NEW_SERIES")` код метода вообще не потребует изменений тела – декоратор сам обернёт выполнение в нужные вызовы. Аналогичным образом должны быть помечены другие ключевые операции (реакции на действия пользователя, запуск оптимизации и т.п.).

- **Лог-файл `solid_state_kinetics.log`** (сырые логи) в новой версии будет содержать явные маркеры операций. Например, можно ожидать строки:
INFO main_window.py:123 - OPERATION START: ADD_NEW_SERIES
...
INFO calculations.py:45 - OPERATION END: ADD_NEW_SERIES
Эти строки могут генерироваться автоматически `start_operation`/`end_operation`. Однако конечный **агрегированный лог** (например, `aggregated.log`) не просто отобразит эти строки, а преобразует их в табличный отчет по операции. Таким образом, `aggregated.log` станет наглядным: помимо уже существующих таблиц (по запросам, по файлам, по построению графиков и т.д.), будут присутствовать таблицы по каждой пользовательской операции. 

- **Пример выходных данных.** Допустим, пользователь последовательно выполняет несколько действий: добавляет серию, запускает оптимизацию, останавливает оптимизацию. В агрегированном логе это отразится тремя таблицами:
1. Таблица операции "ADD_NEW_SERIES" с перечислением подшагов (загрузка файла, получение данных, отрисовка графика и т.д. с их метриками).
2. Таблица операции "START_OPTIMIZATION" (длительный процесс, возможно с особыми метриками от `OptimizationMonitor` – напр. число итераций, финальная точность).
3. Таблица операции "CANCEL_OPTIMIZATION" или "STOP_OPTIMIZATION" (отражающая, что оптимизация была прервана, с соответствующим статусом в таблице).

Эти примеры можно будет увидеть в реальных лог-файлах после рефакторинга, демонстрируя корректность интеграции. **Старые разделы логов** (например, сводки *Request-Response Cycles*, *File Operations Summary* из `aggregated.log`) продолжат присутствовать для паттернов, которые не непосредственно связаны с единичными операциями, но теперь они будут дополняться **операционными сводками**, увязывающими между собой разные паттерны по контексту одной операции.

Важно отметить, что новые изменения **не нарушают работу существующих частей**, а добавляют новые уровни структурирования. Разработчики, читая обновлённый лог, смогут ориентироваться как в разрезе операций пользователя, так и в разрезе типов событий (паттернов), что упростит отладку и анализ работы программы.

## 7. Требования к метрикам и колонкам табличного вывода

Табличное представление операции должно содержать ряд основных метрик, а также быть открытым к расширению. Ниже перечислены **обязательные столбцы** и требования к ним, а также возможность добавления новых:

a. **Продолжительность операции.** В итоговой таблице должна отображаться **длительность каждой операции** в секундах (или миллисекундах для коротких действий) с достаточной точностью. Для этого при `start_operation` нужно фиксировать время начала, при `end_operation` – время завершения; продолжительность вычисляется как разница. Для удобства восприятия можно также отображать время начала и окончания операции (абсолютные временные метки) отдельными колонками, особенно если операции могут пересекаться по времени.

b. **Количество запросов/ответов.** Для каждой операции указывается, сколько **внутренних запросов и ответов** произошло в её рамках. Эта метрика вычисляется с помощью `OperationMonitor`: суммируются все пары request-response, а также учитываются запросы без ответа. В таблице может быть отдельная колонка, например "Calls" или "Req/Res", где стоит число (целое). Например, операция добавления серии данных может генерировать 2 внутренних запроса (запрос данных и запрос расчёта), тогда в колонке будет значение 2. Если операция не подразумевает межкомпонентных запросов, ставится 0.

c. **Расширяемость метрик.** Система должна позволять легко добавлять новые колонки с метриками без значительных изменений кода вывода. Дополнительные колонки вводятся по мере появления новых требований. Примеры потенциальных метрик:
 - **Имя пользователя** – для многопользовательской системы или аудита можно логировать, кто инициировал операцию. Если такой параметр присутствует, таблица получает колонку "User".
 - **Средняя нагрузка CPU** – полезно для длительных операций; вычисляется плагином PerformanceMonitor и отображается, например, как "CPU Avg %".
 - **Статус операции** – текстовый индикатор исхода: *успешно*, *с ошибкой*, *отменено*. Можно отображать значком (✅ для успеха, ⚠️ для предупреждения, ❌ для ошибки) и/или текстом. Статус определяется на основании наличия исключений или вызова отмены в процессе операции.
 - **Количество предупреждений** – если в ходе операции логировались предупреждения (WARNING), их количество может выводиться отдельной колонкой или включаться в статус.
 - **Произвольные метрики домена** – например, для операции оптимизации: число итераций, достигнутая точность, и т.д., которые `OptimizationMonitor` может передать как custom metrics.

Все дополнительные метрики должны **присутствовать только если актуальны**. `OperationTableBuilder` будет проверять наличие значения в `custom_metrics` для текущей операции. Если, к примеру, метрика `cpu_load` не была собрана, колонка "CPU Load" не добавляется, чтобы не загромождать таблицу пустыми полями. Такая динамическая генерация колонок обеспечит, что таблица содержит максимум полезной информации, оставаясь компактной.

Кроме того, нужно убедиться, что формат числовых метрик единообразен (например, время в секундах с двумя знаками после запятой, проценты с одним знаком и т.д.), а текстовые метрики имеют ограничение по ширине или разумно обрезаются, чтобы таблица не теряла читабельность (TabularFormatter имеет возможности адаптивного размера колонок). 

## 8. Тестирование и обновление модульных тестов

Для всех внесённых изменений потребуется написать новые модульные тесты и актуализировать существующие, чтобы гарантировать корректность работы системы агрегации логов:

- **Тесты для OperationAggregator (ручной режим).** Необходимо проверить, что при последовательности вызовов `start_operation`/`end_operation` агрегатор формирует корректные группы операций. Сценарии: одинарная операция (start+end); вложенные операции (start A, start B, end B, end A) – при таком использовании внешний агрегатор должен корректно закрыть внутреннюю операцию B отдельно; последовательные операции (start A, end A, start B, end B) – предыдущая завершается перед началом новой. Также тестируем, что при явном режиме автоматическое объединение по времени не мешает: например, если между start и end пришли лог-сообщения, они обязательно включаются в группу. Если `start_operation` вызывается без последующего `end_operation`, то по истечении таймаута операция завершается автоматически. Юнит-тесты должны охватить и случаи неверного использования (повторный end без start, вложенность start-start-end-end).

- **Тесты для OperationMonitor (метрики).** Проверить, что OperationMonitor правильно считает количество запросов в пределах операции. Можно симулировать несколько вызовов "emit request"/"emit response" и убедиться, что счётчик совпадает. Также протестировать добавление произвольных метрик: вызвать `OperationMonitor.add_metric("user", "Alice")` и убедиться, что после завершения операции эта метрика доступна в данных операции. Если есть логика по таймауту запросов – протестировать, что незакрытый запрос помечается как ошибка/таймаут по прошествии нужного времени. Важно убедиться, что OperationMonitor корректно сбрасывает состояние между операциями (новая операция не содержит метрик предыдущей).

- **Тесты для OperationTableBuilder.** На основе искусственно созданного `OperationGroup` (или аналогичной структуры с заполненными полями подэтапов, времен, метрик) проверить, что `OperationTableBuilder` генерирует нужные заголовки и строки. Например, создать объект с тремя подэтапами, задать им времена и парочку custom_metrics, и убедиться, что на выходе получаем TableData с ожидаемым числом колонок и форматированных строк. Особое внимание – корректность формул длительности (конец-начало), правильное включение/не включение доп. колонок. Также следует протестировать, что значения форматируются в строку правильно (не содержат лишних символов, все столбцы присутствуют).

- **Тесты для TabularFormatter интеграции.** Если добавлен новый тип таблицы, написать тест, который передает в TabularFormatter паттерн типа "operation_summary" с подготовленным TableData, и проверить, что выходная строка содержит правильную ASCII-таблицу (можно сопоставить с образцом или проверить наличие заголовков и разделителей). Также убедиться, что TabularFormatter не ломает существующий функционал: например, форматирование других паттернов (request_response_cycle, file_operations) должно работать как раньше. 

- **Тесты для AggregationEngine и прочих компонентов.** Поскольку AggregationEngine отвечает за сбор агрегированных записей, нужно убедиться, что в цепочке обработки не нарушается общий процесс. Возможно, придется обновить тесты, где предполагалось конкретное количество выводимых агрегированных записей: теперь при включенной опции operation_aggregation может появляться дополнительная запись-таблица на операцию. Следует покрыть случай, когда одновременно включены несколько типов агрегации (операционная, шаблонная, value_aggregation) – система должна корректно обрабатывать их совместно. Например, если один и тот же лог может попасть и в сводку по значению, и в операцию, то приоритет должен быть за операцией (не дублировать вывод). 

Кроме функциональных тестов, **важно запустить весь набор существующих тестов проекта**, связанных с логированием, и убедиться, что они проходят без регрессий. Все изменения должны быть полностью покрыты тестами: это включает как нормальные сценарии, так и граничные случаи (долгая операция, мгновенная операция с 0 длительностью, большое число подэтапов, операция с исключительно предупреждениями/ошибками и т.д.). При необходимости, добавить новые тест-кейсы, отражающие эти ситуации.

----

В результате выполнения данного технического задания система агрегации логов в проекте **solid-state-kinetics** станет более управляемой и информативной. Явная маркировка операций улучшит отслеживаемость действий пользователя, а табличное представление с метриками предоставит структурированный обзор выполнения каждой операции. Все изменения будут выполнены с учётом существующей архитектуры логирования и протестированы, обеспечивая надёжность и удобство сопровождения кода.
